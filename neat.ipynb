{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources of knowledge\n",
    "# the website of the original author talks about issues and parameters of the algorithm https://www.cs.ucf.edu/~kstanley/neat.html\n",
    "# cleared up, what mutation power is supposed to be https://digitalcommons.colby.edu/cgi/viewcontent.cgi?article=1836&context=honorstheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEAT\n",
    "1. Classes and Functions\n",
    "- 1.1. Neural Network (Genotype)->Phenotype, input, output dim, contains mutation: \n",
    "- 1.2. Genotype: A->B: connection gene, A:Node gene, is_disabled, weight, keep track of gene history\n",
    "- 1.3. Crossover (Genotype1, Genotype2)->Genotype12\n",
    "- 1.4. Species, represented by random member\n",
    "- 1.5. Speciation (List of Species)-> List of Species\n",
    "- 1.6. Fitness Calculation (Species)\n",
    "- 1.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "class History:\n",
    "    def __init__(self):\n",
    "        self.last_node_id = 0\n",
    "        self.last_connection_id = 0\n",
    "        self.node_innovations = {}\n",
    "        self.connection_innovations = {}\n",
    "    \n",
    "    def add_node_gene(self, start_node_id, end_node_id): # node is added between start and end\n",
    "        self.last_node_id += 1\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "class Connection_Gene_History:\n",
    "    def __init__(self):\n",
    "        self.innovation_number = 0\n",
    "        self.history = {}\n",
    "    \n",
    "    def get_innovation_number(self, connection):\n",
    "        if connection not in self.history:\n",
    "            self.innovation_number += 1\n",
    "            self.history[connection] = self.innovation_number\n",
    "        \n",
    "        return self.history[connection]\n",
    "    \n",
    "    def __contains__(self, connection):\n",
    "        return connection in self.history\n",
    "    \n",
    "    def init_new_history(self):\n",
    "        # \"overwrites all previous history keys\"\n",
    "        temp_history = {}\n",
    "        for k,v in self.history.items():\n",
    "            temp_history[str(k)+'o'] = v\n",
    "        \n",
    "        self.history = temp_history\n",
    "        \n",
    "\n",
    "class Node_Gene_History:\n",
    "    def __init__(self):\n",
    "        self.innovation_number = -1\n",
    "        self.history = {}\n",
    "        self.node_levels = {}\n",
    "    \n",
    "    def get_innovation_number(self, connection, src_node, dst_node):\n",
    "        \n",
    "        if connection not in self.history:\n",
    "            self.innovation_number += 1\n",
    "            self.history[connection] = self.innovation_number\n",
    "            \n",
    "            dst_level = self.node_levels[dst_node]\n",
    "            if self.node_levels[src_node]+1 == dst_level:\n",
    "                for k,v in self.node_levels.items():\n",
    "                    if v >= dst_level:\n",
    "                        self.node_levels[k] +=1 # increase level of all nodes with at least dst node level\n",
    "            self.node_levels[self.innovation_number] = self.node_levels[src_node]+1\n",
    "        \n",
    "        return self.history[connection]\n",
    "    \n",
    "    def add_initial_node(self, node_level, node_id=None):\n",
    "        if node_id is not None:\n",
    "            if self.innovation_number < node_id:\n",
    "                self.innovation_number = node_id\n",
    "            self.history[str(self.innovation_number)] = node_id\n",
    "        else:\n",
    "            self.innovation_number += 1\n",
    "            self.history[str(self.innovation_number)] = self.innovation_number\n",
    "        \n",
    "        self.node_levels[self.innovation_number] = node_level\n",
    "        \n",
    "        if node_id is not None:\n",
    "            return node_id\n",
    "        return self.innovation_number\n",
    "    \n",
    "    def __contains__(self, connection):\n",
    "        return connection in self.history\n",
    "\n",
    "    def init_new_history(self):\n",
    "        # \"overwrites all previous history keys\"\n",
    "        temp_history = {}\n",
    "        for k,v in self.history.items():\n",
    "            temp_history[str(k)+'o'] = v\n",
    "        \n",
    "        self.history = temp_history\n",
    "\n",
    "\n",
    "class Node_Gene:\n",
    "    def __init__(self, src_node, dst_node, node_gene_history:Node_Gene_History, add_initial=False, add_initial_node_level=None, initial_node_id=None):\n",
    "        connection = str(src_node)+'->'+str(dst_node)\n",
    "        if add_initial:\n",
    "            self.innovation_number = node_gene_history.add_initial_node( add_initial_node_level, node_id=initial_node_id)\n",
    "        else:\n",
    "            self.innovation_number = node_gene_history.get_innovation_number( connection, src_node, dst_node)\n",
    "          \n",
    "        #self.src_node = src_node\n",
    "        #self.dst_node = dst_node\n",
    "\n",
    "class Connection_Gene:\n",
    "    def __init__(self, in_node, out_node, weight, is_disabled, connection_gene_history:Connection_Gene_History):\n",
    "        connection = str(in_node)+'->'+str(out_node)\n",
    "        self.in_node = in_node\n",
    "        self.out_node = out_node\n",
    "        self.weight = weight\n",
    "        self.is_disabled = is_disabled\n",
    "        self.innovation_number = connection_gene_history.get_innovation_number(connection)\n",
    "        \n",
    "            \n",
    "class Genotype:\n",
    "    def __init__(self, node_genes, connection_genes,\n",
    "                 node_gene_history:Node_Gene_History, connection_gene_history:Connection_Gene_History,\n",
    "                 mutate_weight_prob, mutate_weight_perturb, mutate_weight_random, mutate_add_node_prob, mutate_add_link_prob, weight_magnitude\n",
    "                 ,c1, c2, c3\n",
    "                 \n",
    "                 ):\n",
    "        \n",
    "        self.node_genes = node_genes\n",
    "        self.connection_genes = connection_genes\n",
    "        self.node_gene_history = node_gene_history\n",
    "        self.connection_gene_history = connection_gene_history\n",
    "        self.mutate_weight_prob = mutate_weight_prob\n",
    "        self.mutate_weight_perturb = mutate_weight_perturb\n",
    "        self.mutate_weight_random = mutate_weight_random\n",
    "        self.mutate_add_node_prob = mutate_add_node_prob\n",
    "        self.mutate_add_link_prob = mutate_add_link_prob\n",
    "        self.node_genes_dict = {node_gene.innovation_number:node_gene for node_gene in self.node_genes}\n",
    "        self.connection_genes_dict = {connection_gene.innovation_number:connection_gene for connection_gene in self.connection_genes}\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.c3 = c3\n",
    "        self.weight_magnitude = weight_magnitude\n",
    "    \n",
    "    def print_genotype(self):\n",
    "        # in pd table\n",
    "        node_genes = pd.DataFrame([[node_gene.innovation_number, self.node_gene_history.node_levels[node_gene.innovation_number]] for node_gene in self.node_genes], columns=['innovation_number', 'node_level'])\n",
    "        connection_genes = pd.DataFrame([[connection_gene.innovation_number, connection_gene.in_node, connection_gene.out_node, connection_gene.weight, connection_gene.is_disabled] for connection_gene in self.connection_genes], columns=['innovation_number','in_node', 'out_node', 'weight', 'is_disabled'])\n",
    "        \n",
    "        print('Node genes:')\n",
    "        print(node_genes)\n",
    "        print('Connection genes:')\n",
    "        print(connection_genes)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def mutate(self, mutate_add_link_prob=None):\n",
    "        if mutate_add_link_prob is None:\n",
    "            mutate_add_link_prob = self.mutate_add_link_prob\n",
    "        \n",
    "        # mutate weight\n",
    "        # random boolean  mask\n",
    "        mask = np.random.rand(len(self.connection_genes)) <= self.mutate_weight_prob\n",
    "        \n",
    "        for connection_gene in np.array(self.connection_genes)[mask]:\n",
    "            if np.random.rand() < self.mutate_weight_perturb:\n",
    "                connection_gene.weight += np.random.normal() * self.weight_magnitude\n",
    "            else:\n",
    "                connection_gene.weight = np.random.normal() * self.weight_magnitude\n",
    "        \n",
    "     \n",
    "        \n",
    "        # mutate add node\n",
    "        if np.random.rand() < self.mutate_add_node_prob:\n",
    "            self.add_node()\n",
    "\n",
    "        # mutate add link\n",
    "        if np.random.rand() < mutate_add_link_prob:\n",
    "            self.add_connection()\n",
    "            \n",
    "        # # mutate remove node\n",
    "        # if np.random.rand() < self.mutate_add_node_prob*0.6:\n",
    "        #     self.remove_node()\n",
    "        \n",
    "        # mutate remove link\n",
    "        if np.random.rand() < mutate_add_link_prob:\n",
    "            self.remove_connection()\n",
    "    \n",
    "    def remove_node(self):\n",
    "        # select a random node gene\n",
    "        if len(self.node_genes) == 0:\n",
    "            return\n",
    "        \n",
    "        node_gene = np.random.choice(self.node_genes)\n",
    "        self.node_genes.remove(node_gene)\n",
    "        del self.node_genes_dict[node_gene.innovation_number]\n",
    "        \n",
    "        # remove connection genes\n",
    "        # save the in and out node of the connection gene\n",
    "        in_nodes = []\n",
    "        out_nodes = []\n",
    "        for connection_gene in self.connection_genes:\n",
    "            if connection_gene.in_node == node_gene.innovation_number or connection_gene.out_node == node_gene.innovation_number:\n",
    "                if connection_gene.in_node not in in_nodes:\n",
    "                    in_nodes.append(connection_gene.in_node)\n",
    "                elif connection_gene.out_node not in out_nodes:\n",
    "                    out_nodes.append(connection_gene.out_node)\n",
    "                    \n",
    "                self.connection_genes.remove(connection_gene)\n",
    "                del self.connection_genes_dict[connection_gene.innovation_number]\n",
    "        \n",
    "        # enable previous connection genes\n",
    "        for connection_gene in self.connection_genes:\n",
    "            if connection_gene.in_node in in_nodes and connection_gene.out_node in out_nodes:\n",
    "                connection_gene.is_disabled = False\n",
    "    \n",
    "    def remove_connection(self):\n",
    "        # select a random connection gene\n",
    "        if len(self.connection_genes) == 0:\n",
    "            return\n",
    "        \n",
    "        connection_gene = np.random.choice(self.connection_genes)\n",
    "        connection_gene.is_disabled = True\n",
    "    \n",
    "    def add_node(self):\n",
    "        # select a random connection gene\n",
    "        \n",
    "        non_disabled_connection_genes = [connection_gene for connection_gene in self.connection_genes if not connection_gene.is_disabled]\n",
    "        if len(non_disabled_connection_genes) == 0:\n",
    "            return\n",
    "        \n",
    "        connection_gene = np.random.choice(non_disabled_connection_genes)\n",
    "        connection_gene.is_disabled = True\n",
    "        \n",
    "        # add node gene\n",
    "        node_gene = Node_Gene(connection_gene.in_node, connection_gene.out_node, self.node_gene_history)\n",
    "        self.node_genes.append(node_gene)\n",
    "        self.node_genes_dict[node_gene.innovation_number] = node_gene\n",
    "        \n",
    "        # add connection genes, first weight is 1.0, second is the one of the original\n",
    "        connection_gene1 = Connection_Gene(connection_gene.in_node, node_gene.innovation_number, 1.0, False, self.connection_gene_history)\n",
    "        connection_gene2 = Connection_Gene(node_gene.innovation_number, connection_gene.out_node, connection_gene.weight, False, self.connection_gene_history)\n",
    "        self.connection_genes.append(connection_gene1)\n",
    "        self.connection_genes.append(connection_gene2)\n",
    "        self.connection_genes_dict[connection_gene1.innovation_number] = connection_gene1\n",
    "        self.connection_genes_dict[connection_gene2.innovation_number] = connection_gene2\n",
    "    \n",
    "    def add_connection(self):\n",
    "        permuted = np.random.permutation(self.node_genes)\n",
    "        node_levels = {}\n",
    "        for node_gene in permuted:\n",
    "            lvl = self.node_gene_history.node_levels[node_gene.innovation_number]\n",
    "            if lvl not in node_levels:\n",
    "                node_levels[lvl] = [node_gene]\n",
    "            else:\n",
    "                node_levels[lvl].append(node_gene)\n",
    "        \n",
    "        for src in permuted:\n",
    "            level = self.node_gene_history.node_levels[src.innovation_number]\n",
    "            dsts = []\n",
    "            for k, v in node_levels.items():\n",
    "                if k > level:\n",
    "                    dsts.extend(v)\n",
    "            permuted_dst = np.random.permutation(dsts)\n",
    "            for dst in permuted_dst:\n",
    "                connection = str(src.innovation_number)+'->'+str(dst.innovation_number)\n",
    "                \n",
    "                # if connection in history but not in genotype (with or without connection being from previous evolution steps)\n",
    "                # add connection gene to genotype\n",
    "                # if connection not in history:\n",
    "                # add connection gene to genotype\n",
    "                # if connection in genotype but disabled:\n",
    "                # enable connection gene\n",
    "                \n",
    "                connection_in_history = False\n",
    "                connection_name = None\n",
    "                for key in self.connection_gene_history.history.keys():\n",
    "                    if key.startswith(connection):\n",
    "                        connection_in_history = True\n",
    "                        connection_name = key\n",
    "                        break\n",
    "                \n",
    "                if not connection_in_history:\n",
    "                    # add connection gene\n",
    "                    connection_gene = Connection_Gene(src.innovation_number, dst.innovation_number, np.random.normal(), False, self.connection_gene_history)\n",
    "                    self.connection_genes.append(connection_gene)\n",
    "                    self.connection_genes_dict[connection_gene.innovation_number] = connection_gene\n",
    "                    return\n",
    "                elif self.connection_gene_history.history[connection_name] not in self.connection_genes_dict:\n",
    "                    # add connection gene\n",
    "                    connection_gene = Connection_Gene(src.innovation_number, dst.innovation_number, np.random.normal(), False, self.connection_gene_history)\n",
    "                    self.connection_genes.append(connection_gene)\n",
    "                    self.connection_genes_dict[connection_gene.innovation_number] = connection_gene\n",
    "                    return\n",
    "                elif self.connection_genes_dict[self.connection_gene_history.history[connection_name]].is_disabled: # if connection is disabled we take it and enable\n",
    "                    self.connection_genes_dict[self.connection_gene_history.history[connection_name]].is_disabled = False\n",
    "                    return\n",
    "                \n",
    "                \n",
    "                # if connection not in the network\n",
    "                # for key in self.connection_gene_history.history.keys():\n",
    "                #     if key.startswith(connection):\n",
    "                    \n",
    "                # print(self.connection_gene_history.history)\n",
    "                # if self.connection_gene_history.history[connection] not in self.connection_genes_dict:\n",
    "                #     # add connection gene\n",
    "                #     connection_gene = Connection_Gene(src.innovation_number, dst.innovation_number, np.random.normal(), False, self.connection_gene_history)\n",
    "                #     self.connection_genes.append(connection_gene)\n",
    "                #     self.connection_genes_dict[connection_gene.innovation_number] = connection_gene\n",
    "                #     return # only add connection if one is possible\n",
    "                # elif self.connection_genes_dict[self.connection_gene_history.history[connection]].is_disabled: # if connection is disabled we take it and enable\n",
    "                #     self.connection_genes_dict[self.connection_gene_history.history[connection]].is_disabled = False\n",
    "                #     return \n",
    "    \n",
    "    def _crossover_genes(self, fitness_self, fitness_other, genes_self, genes_other):\n",
    "        more_fit = genes_self if fitness_self > fitness_other else genes_other\n",
    "        less_fit = genes_self if fitness_self < fitness_other else genes_other\n",
    "        \n",
    "        # create new node genes\n",
    "        more_fit_innovations = set([gene.innovation_number for gene in more_fit])\n",
    "        less_fit_innovations = set([gene.innovation_number for gene in less_fit])\n",
    "        \n",
    "        overlap = np.array(list(more_fit_innovations.intersection(less_fit_innovations)))\n",
    "        disjoint = np.array(list(more_fit_innovations - less_fit_innovations)) # disjoint and excess of more fit\n",
    "        \n",
    "        mask = np.random.choice([True, False], len(overlap))\n",
    "       \n",
    "        if len(disjoint) > 0:\n",
    "            from_more_fit = np.concatenate([overlap[mask], disjoint])\n",
    "        else:\n",
    "            from_more_fit = overlap[mask]\n",
    "            \n",
    "        from_less_fit = overlap[~mask]\n",
    "        genes1 = [node_gene for node_gene in more_fit if node_gene.innovation_number in from_more_fit]\n",
    "        genes2 = [node_gene for node_gene in less_fit if node_gene.innovation_number in from_less_fit]\n",
    "        \n",
    "\n",
    "        genes1.extend(genes2)\n",
    "        return [deepcopy(gene) for gene in genes1]\n",
    "    \n",
    "    def crossover(self, other, fitness_self, fitness_other):\n",
    "        node_genes = self._crossover_genes(fitness_self, fitness_other, self.node_genes, other.node_genes)\n",
    "        connection_genes = self._crossover_genes(fitness_self, fitness_other, self.connection_genes, other.connection_genes)\n",
    "        return Genotype(node_genes, connection_genes, self.node_gene_history, self.connection_gene_history, self.mutate_weight_prob, self.mutate_weight_perturb, self.mutate_weight_random, self.mutate_add_node_prob, self.mutate_add_link_prob, self.weight_magnitude, self.c1, self.c2, self.c3)\n",
    "    \n",
    "    \n",
    "    def _distance(self, genes, genes_other):\n",
    "        genes = [gene.innovation_number for gene in genes]\n",
    "        genes = sorted(genes)\n",
    "        other_genes = [gene.innovation_number for gene in genes_other]\n",
    "        other_genes = sorted(other_genes)\n",
    "        \n",
    "        max_innovation_number_self = genes[-1]\n",
    "        max_innovation_number_other = other_genes[-1]\n",
    "        \n",
    "        \n",
    "        matching_genes = []\n",
    "        disjoint_genes_self = []\n",
    "        disjoint_genes_other = []\n",
    "        excess_genes = []\n",
    "        \n",
    "        for innovation_number in range(min(max_innovation_number_self, max_innovation_number_other)+1):\n",
    "            if innovation_number in genes and innovation_number in other_genes:\n",
    "                matching_genes.append(innovation_number)\n",
    "            elif innovation_number in genes:\n",
    "                disjoint_genes_self.append(innovation_number)\n",
    "            elif innovation_number in other_genes:\n",
    "                disjoint_genes_other.append(innovation_number)\n",
    "                \n",
    "        excess_genes =  set(genes).union(set(other_genes)) - set(matching_genes).union(set(disjoint_genes_self)).union(set(disjoint_genes_other))\n",
    "        return matching_genes, disjoint_genes_self, disjoint_genes_other, excess_genes\n",
    "    \n",
    "        \n",
    "    def distance(self, other):\n",
    "        M_n, D_self_n, D_other_n, E_n = self._distance(self.node_genes, other.node_genes)\n",
    "        M_c, D_self_c, D_c, E_c= self._distance(self.connection_genes, other.connection_genes)\n",
    "        \n",
    "        D = len(D_self_n) + len(D_other_n) + len(D_self_c) + len(D_c)\n",
    "        E = len(E_n) + len(E_c)\n",
    "        \n",
    "        # calculate average weight difference of matching genes\n",
    "        W = 0\n",
    "        for innovation_number in M_c:\n",
    "            W += np.abs(self.connection_genes_dict[innovation_number].weight - other.connection_genes_dict[innovation_number].weight)\n",
    "        \n",
    "        W = W/len(M_c)\n",
    "        N = max(len(self.node_genes) + len(self.connection_genes), len(other.node_genes)+len(other.connection_genes))\n",
    "       \n",
    "        return self.c1*E/N + self.c2*D/N + self.c3*W\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.node_genes) + '\\n' + str(self.connection_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from typing import Dict \n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + torch.exp(-4.9*x))\n",
    "    \n",
    "    \n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, genotype:Genotype):\n",
    "        self.genotype = genotype\n",
    "        self.connection_genes = genotype.connection_genes\n",
    "    \n",
    "        # create nn\n",
    "        self.connections_per_level = {}\n",
    "        self.connections = {}\n",
    "        \n",
    "        for connection_gene in [gene for gene in self.connection_genes if not gene.is_disabled]:\n",
    "            self.connections[connection_gene.innovation_number] = torch.nn.Linear(1, 1, bias=False)\n",
    "            # specify weight\n",
    "            self.connections[connection_gene.innovation_number].weight = torch.nn.Parameter(torch.tensor([connection_gene.weight]))\n",
    "            self.connections[connection_gene.innovation_number].weight.requires_grad_(False)\n",
    "            \n",
    "            src_node = connection_gene.in_node\n",
    "            dst_node = connection_gene.out_node\n",
    "            dst_node_level = self.genotype.node_gene_history.node_levels[dst_node]\n",
    "            \n",
    "            if dst_node_level not in self.connections_per_level:\n",
    "                self.connections_per_level[dst_node_level] = {dst_node:{}}\n",
    "            elif dst_node not in self.connections_per_level[dst_node_level]:\n",
    "                self.connections_per_level[dst_node_level][dst_node] = {}\n",
    "            \n",
    "            \n",
    "            self.connections_per_level[dst_node_level][dst_node][src_node] = self.connections[connection_gene.innovation_number]\n",
    "        \n",
    "       \n",
    "        \n",
    "            \n",
    "        self.sorted_levels = sorted(self.connections_per_level.keys())               \n",
    "    \n",
    "    \n",
    "    def print_nn(self):\n",
    "        # format nicely\n",
    "        i = 0\n",
    "        for level in reversed(self.sorted_levels):\n",
    "            i+=1\n",
    "            for node in self.connections_per_level[level]:\n",
    "                print(' '*i*3+'Node:', node)\n",
    "                for src_node in self.connections_per_level[level][node]:\n",
    "                    print(' '*i*6+ 'src:', src_node, 'level:',self.genotype.node_gene_history.node_levels[src_node],'weight:', self.connections_per_level[level][node][src_node].weight.data)\n",
    "    \n",
    "    def forward(self, x:Dict[int, float]):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            node_repr = x \n",
    "            for level in self.sorted_levels:\n",
    "                for node in self.connections_per_level[level]:\n",
    "                    input = torch.tensor([0.0])\n",
    "                    for src_node in self.connections_per_level[level][node]:\n",
    "                        try:\n",
    "                            input += self.connections_per_level[level][node][src_node](node_repr[src_node])\n",
    "                        except KeyError:\n",
    "                            print('KeyError')\n",
    "                            print(node_repr)\n",
    "                            print(src_node)\n",
    "                            print(node)\n",
    "                            print(self.connections_per_level)\n",
    "                            print(self.connections_per_level[level])\n",
    "                            print(self.connections_per_level[level][node])\n",
    "                            print(self.connections_per_level[level][node][src_node])\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                    node_repr[node] = sigmoid(input)\n",
    "            \n",
    "            return node_repr[list(self.connections_per_level[self.sorted_levels[-1]].keys())[0]]\n",
    "\n",
    "# nn = NeuralNetwork(genotype1)\n",
    "# x = {0:torch.tensor([-1.0]),1:torch.tensor([0.3])}\n",
    "# nn.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from datetime import datetime \n",
    "from tqdm.auto import tqdm\n",
    "class Species:\n",
    "    def __init__(self, representative, genotypes, distance_delta):\n",
    "        # random representative\n",
    "        self.representative = representative\n",
    "        self.distance_delta = distance_delta\n",
    "        self.genotypes = genotypes\n",
    "        self.best_fitness = -np.inf\n",
    "        self.last_best_fitness_generation = 0\n",
    "\n",
    "    def add_to_genotype(self, genotype):\n",
    "        distance = self.representative.distance(genotype)\n",
    "        if distance < self.distance_delta:\n",
    "            self.genotypes.append(genotype)\n",
    "            return True \n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def get_proportional_bins(proportions, n_bins):\n",
    "    \n",
    "    proportions = proportions.flatten()\n",
    "    proportions = proportions/sum(proportions)\n",
    "    \n",
    "    bins = np.round(proportions * n_bins).astype(int)\n",
    "    while sum(bins) != n_bins:\n",
    "        if sum(bins) > n_bins:\n",
    "            # remove one in random bin\n",
    "            index = np.random.choice(np.arange(len(bins)))\n",
    "            bins[index] -= 1\n",
    "        elif sum(bins) < n_bins:\n",
    "            # add one in random bin\n",
    "            index = np.random.choice(np.arange(len(bins)))\n",
    "            bins[index] += 1\n",
    "    \n",
    "    return bins\n",
    "\n",
    "def evolve_once(features, target, \n",
    "                fitness_function, stop_at_fitness:float, \n",
    "                species:List[Species],fitness_survival_rate, interspecies_mate_rate, distance_delta,\n",
    "                largest_species_linkadd_rate,\n",
    "                ):\n",
    "    \n",
    "    Node_Gene_History = species[0].representative.node_gene_history\n",
    "    Connection_Gene_History = species[0].representative.connection_gene_history\n",
    "    # reinit\n",
    "    Node_Gene_History.init_new_history()\n",
    "    Connection_Gene_History.init_new_history()\n",
    "    \n",
    "    #top_species_fitness = []\n",
    "    top_species_adjusted_fitness = []\n",
    "    species_total_adjusted_fitness = []\n",
    "    \n",
    "    fittest_networks = {}\n",
    "\n",
    "    species_with_increased_fitness_last15gens = []\n",
    "    stop_marker = False\n",
    "    for i, sp in enumerate(species):\n",
    "        if len(sp.genotypes) == 0:\n",
    "            continue\n",
    "        \n",
    "        adjusted_fitnesses = []\n",
    "        for genotype in sp.genotypes:\n",
    "            \n",
    "            network = NeuralNetwork(genotype)\n",
    "            fitness = fitness_function(network, features, target)\n",
    "            fitness = fitness.item()\n",
    "            \n",
    "            if fitness>=stop_at_fitness:\n",
    "                if i not in fittest_networks:\n",
    "                    fittest_networks[i] = []\n",
    "                fittest_networks[i].append((genotype, fitness))\n",
    "                stop_marker = True\n",
    "                \n",
    "            adjusted_fitnesses.append(fitness/len(sp.genotypes))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # don't allow reproduction if no fitness improvement for 15 generations\n",
    "        \n",
    "        max_fitness = max(adjusted_fitnesses)\n",
    "            \n",
    "        if max_fitness > sp.best_fitness:\n",
    "            sp.best_fitness = max_fitness\n",
    "            sp.last_best_fitness_generation = 0\n",
    "        else: \n",
    "            sp.last_best_fitness_generation += 1\n",
    "            if sp.last_best_fitness_generation > 20 and not len(species) == 1:\n",
    "                continue\n",
    "        \n",
    "        species_with_increased_fitness_last15gens.append(sp) # only allow reproduction if fitness increased\n",
    "        \n",
    "        \n",
    "        \n",
    "        species_total_adjusted_fitness.append(sum(adjusted_fitnesses))\n",
    "        mask = np.argsort(adjusted_fitnesses)\n",
    "        top_n_fitness_indices = mask[-int(fitness_survival_rate*len(adjusted_fitnesses)):]\n",
    "        fit_individuals = [(genotype, fitness) for genotype, fitness in zip(np.array(sp.genotypes)[top_n_fitness_indices], np.array(adjusted_fitnesses)[top_n_fitness_indices])]\n",
    "        # sort by fitness\n",
    "        fit_individuals = sorted(fit_individuals, key=lambda x: x[1], reverse=False)\n",
    "        top_species_adjusted_fitness.append(fit_individuals)\n",
    "        print('Species:', i, 'fitness:', sum(adjusted_fitnesses), 'best fitness:', max(adjusted_fitnesses))\n",
    "        \n",
    "    # sum over connection_genes\n",
    "    # for sp in species_with_increased_fitness_last15gens:\n",
    "    #     x = 0\n",
    "    #     for genotype in sp.genotypes:\n",
    "    #         x += len(genotype.connection_genes)\n",
    "    #     print('avg connections:', x/len(sp.genotypes))\n",
    "                \n",
    "    \n",
    "    \n",
    "    if stop_marker:\n",
    "        return species, True, fittest_networks\n",
    "    \n",
    "    total_offsprings = sum([len(sp.genotypes) for sp in species])\n",
    "    proportions = np.array([species_total_adjusted_fitness[i]/sum(species_total_adjusted_fitness) for i in range(len(species_total_adjusted_fitness))])\n",
    "\n",
    "    # inner- and interspecies mating proportions\n",
    "    inter_species_number_of_offsprings = get_proportional_bins(proportions, total_offsprings)\n",
    "    inner_species_number_of_offsprings_probabilities = []\n",
    "    for fit_individuals ,no_offsprings in zip(top_species_adjusted_fitness, inter_species_number_of_offsprings):\n",
    "        fitnesses = np.array([fitness for _, fitness in fit_individuals])\n",
    "        inner_species_number_of_offsprings_probabilities.append([fitness/sum(fitnesses) for fitness in fitnesses])\n",
    "    \n",
    "    new_genotypes = []\n",
    "    \n",
    "    # interspecies mating\n",
    "    if np.random.rand() < interspecies_mate_rate and len(species_with_increased_fitness_last15gens) > 1:\n",
    "        # pick two species without replacement\n",
    "        pair = np.random.choice(np.arange(len(species_with_increased_fitness_last15gens)), 2, replace=False)\n",
    "        # pick top performers from both species\n",
    "        genotype1, fitness1 = top_species_adjusted_fitness[pair[0]][-1] \n",
    "        genotype2, fitness2 = top_species_adjusted_fitness[pair[1]][-1]\n",
    "        \n",
    "        new_genotype = genotype1.crossover(genotype2, fitness1, fitness2)\n",
    "        new_genotypes.append(new_genotype)\n",
    "        # remove 1 from fit species\n",
    "        if fitness1 > fitness2:\n",
    "            which = pair[0]\n",
    "        else:\n",
    "            which = pair[1]\n",
    "        \n",
    "        inter_species_number_of_offsprings[which] -= 1 # remove one from fit species\n",
    "    \n",
    "    \n",
    "  \n",
    "    largest_species = [False for _ in range(len(species_with_increased_fitness_last15gens))]\n",
    "    largest_species[np.argmax([len(sp.genotypes) for sp in species_with_increased_fitness_last15gens])] = True\n",
    "    # innerspecies mating\n",
    "    # we implement it using probablitlies to select parents\n",
    "    for fit_individuals, no_offsprings, probabilities, is_largest_species in zip(top_species_adjusted_fitness, inter_species_number_of_offsprings, inner_species_number_of_offsprings_probabilities,largest_species):\n",
    "        fit_individuals = [genotype for genotype, _ in fit_individuals]\n",
    "        \n",
    "        # 25% of offsprings are without crossover\n",
    "        without_crossover = int(0.25 * no_offsprings)\n",
    "        for i in range(no_offsprings):\n",
    "            # 25% of offsprings are without crossover\n",
    "            if i<=without_crossover:\n",
    "                parent1 = np.random.choice(fit_individuals, 1, replace=False, p=probabilities)[0]\n",
    "                parent2 = parent1\n",
    "                \n",
    "            elif len(fit_individuals) == 1: # if there is a new species, there will only be one individual in it\n",
    "                parent1 = fit_individuals[0]\n",
    "                parent2 = fit_individuals[0]\n",
    "            else: # pick two parents\n",
    "                parent1, parent2 = np.random.choice(fit_individuals, 2, replace=False, p=probabilities)\n",
    "                \n",
    "            new_genotype = parent1.crossover(parent2, 1, 1)\n",
    "            # mutate\n",
    "            if is_largest_species:\n",
    "                new_genotype.mutate(mutate_add_link_prob=largest_species_linkadd_rate)\n",
    "            else:\n",
    "                new_genotype.mutate()\n",
    "            new_genotypes.append(new_genotype)\n",
    "    \n",
    "    # remove old genotypes, except reference genotype\n",
    "    for sp in species:\n",
    "        sp.genotypes = []\n",
    "    \n",
    "    # speciate\n",
    "    new_species = species_with_increased_fitness_last15gens\n",
    "    for genotype in new_genotypes:\n",
    "        added = False\n",
    "        for sp in new_species:\n",
    "            added = sp.add_to_genotype(genotype)\n",
    "            if added:                \n",
    "                break\n",
    "            \n",
    "        if not added:\n",
    "            new_species.append(Species(genotype, [genotype], distance_delta))\n",
    "    \n",
    "    return new_species, False, None\n",
    "        \n",
    "def evolve(features, target, fitness_function, stop_at_fitness:float, n_generations, species:Species, fitness_survival_rate, interspecies_mate_rate, distance_delta, largest_species_linkadd_rate):\n",
    "    for i in range(n_generations):\n",
    "        species, found_solution, solutions = evolve_once(features, target, fitness_function, stop_at_fitness, species, fitness_survival_rate, interspecies_mate_rate, distance_delta, largest_species_linkadd_rate )\n",
    "        if found_solution:\n",
    "            return species, solutions\n",
    "        print(i)\n",
    "\n",
    "    return species, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor_fitness(network:NeuralNetwork, inputs, targets, print_fitness=False):\n",
    "    error = 0\n",
    "    for input, target in zip(inputs, targets):\n",
    "        output = network.forward(input)\n",
    "        error += torch.abs(output - target)\n",
    "        if print_fitness:\n",
    "            print('target', target, 'output', output, 'error', error)\n",
    "    \n",
    "   \n",
    "    fitness = (4 - error)**2\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolver:\n",
    "import random \n",
    "random.seed(14)\n",
    "n_networks = 150\n",
    "\n",
    "# Fitness:\n",
    "c1 = 1\n",
    "c2 = 1\n",
    "c3 = 0.4\n",
    "distance_delta = 6\n",
    "\n",
    "\n",
    "weight_magnitude = 2.5 # std of weight mutation\n",
    "# Mutation\n",
    "mutate_weight_prob = 0.8\n",
    "mutate_weight_perturb = 0.8\n",
    "mutate_weight_random = 1 - mutate_weight_perturb\n",
    "mutate_add_node_prob = 0.02\n",
    "mutate_add_link_prob_large_pop = 0.08\n",
    "mutate_add_link_prob = 0.02\n",
    "\n",
    "offspring_without_crossover = 0.25\n",
    "interspecies_mate_rate = 0.001\n",
    "\n",
    "fitness_survival_rate = 0.2\n",
    "interspecies_mate_rate = 0.001\n",
    "\n",
    "\n",
    "node_gene_history = Node_Gene_History()\n",
    "connection_gene_history = Connection_Gene_History()\n",
    "\n",
    "genotypes = []\n",
    "\n",
    "\n",
    "for _ in range(n_networks):\n",
    "    node_genes = [\n",
    "        Node_Gene(None, None, node_gene_history, add_initial=True, add_initial_node_level=0, initial_node_id=0), \n",
    "        Node_Gene(None, None, node_gene_history, add_initial=True, add_initial_node_level=0, initial_node_id=1),\n",
    "        Node_Gene(None, None, node_gene_history, add_initial=True, add_initial_node_level=0, initial_node_id=2),\n",
    "        Node_Gene(None, None, node_gene_history, add_initial=True, add_initial_node_level=1, initial_node_id=3)\n",
    "    ]\n",
    "    \n",
    "    connection_genes = [\n",
    "        Connection_Gene(0, 3, np.random.normal(), False, connection_gene_history), # bias\n",
    "        Connection_Gene(1, 3, np.random.normal(), False, connection_gene_history), # input 1 \n",
    "        Connection_Gene(2, 3, np.random.normal(), False, connection_gene_history), # input 2\n",
    "    ]\n",
    "    \n",
    "    genotype = Genotype(\n",
    "        node_genes, connection_genes, node_gene_history, connection_gene_history, \n",
    "        mutate_weight_prob, mutate_weight_perturb, mutate_weight_random, mutate_add_node_prob, mutate_add_link_prob, weight_magnitude,\n",
    "        c1, c2, c3)\n",
    "    genotypes.append(genotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor\n",
    "inputs = [\n",
    "    {0:torch.tensor([1.0]),1:torch.tensor([0.0]),2:torch.tensor([0.0])},\n",
    "    {0:torch.tensor([1.0]),1:torch.tensor([1.0]),2:torch.tensor([0.0])},\n",
    "    {0:torch.tensor([1.0]),1:torch.tensor([0.0]),2:torch.tensor([1.0])},\n",
    "    {0:torch.tensor([1.0]),1:torch.tensor([1.0]),2:torch.tensor([1.0])}\n",
    "    # xor:\n",
    "    # bias 1, 00, 01, 10, 11\n",
    "]\n",
    "targets = [\n",
    "    torch.tensor([0.0]),\n",
    "    torch.tensor([1.0]),\n",
    "    torch.tensor([1.0]),\n",
    "    torch.tensor([0.0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species: 0 fitness: 4.1850767985979695 best fitness: 0.055334828694661456\n",
      "0\n",
      "Species: 0 fitness: 4.5645161175727855 best fitness: 0.0598019536336263\n",
      "1\n",
      "Species: 0 fitness: 4.553856163819629 best fitness: 0.059801731109619144\n",
      "2\n",
      "Species: 0 fitness: 4.906252009073895 best fitness: 0.05999998092651367\n",
      "3\n",
      "Species: 0 fitness: 5.384352280298868 best fitness: 0.06\n",
      "4\n",
      "Species: 0 fitness: 5.472862015565237 best fitness: 0.05999996185302734\n",
      "5\n",
      "Species: 0 fitness: 5.639480665524798 best fitness: 0.06\n",
      "6\n",
      "Species: 0 fitness: 5.8386118634541795 best fitness: 0.06\n",
      "7\n",
      "Species: 0 fitness: 6.316097333431239 best fitness: 0.06\n",
      "8\n",
      "Species: 0 fitness: 6.534816351731617 best fitness: 0.06\n",
      "9\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([0.]), 2: tensor([0.]), 3: tensor([4.6158e-14]), 4: tensor([0.5000]), 5: tensor([0.9926]), 6: tensor([0.5000]), 7: tensor([0.5000]), 8: tensor([0.5000]), 9: tensor([0.5000]), 10: tensor([0.5000]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.5000]), 14: tensor([0.9926]), 15: tensor([0.0043]), 16: tensor([0.5000]), 17: tensor([0.5000])}\n",
      "18\n",
      "3\n",
      "{2: {3: {0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([1.]), 2: tensor([0.]), 3: tensor([7.4301e-37]), 4: tensor([0.9926]), 5: tensor([0.9926]), 6: tensor([0.9926]), 7: tensor([0.5000]), 8: tensor([0.9926]), 9: tensor([0.9926]), 10: tensor([0.5000]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.5000]), 14: tensor([0.9926]), 15: tensor([0.0043]), 16: tensor([0.9926]), 17: tensor([0.9926])}\n",
      "18\n",
      "3\n",
      "{2: {3: {0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([0.]), 2: tensor([1.]), 3: tensor([1.0000]), 4: tensor([0.5000]), 5: tensor([0.9926]), 6: tensor([0.5000]), 7: tensor([0.9926]), 8: tensor([0.5000]), 9: tensor([0.5000]), 10: tensor([0.9926]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.9926]), 14: tensor([0.9926]), 15: tensor([0.1607]), 16: tensor([0.5000]), 17: tensor([0.5000])}\n",
      "18\n",
      "3\n",
      "{2: {3: {0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([1.]), 2: tensor([1.]), 3: tensor([1.7644e-17]), 4: tensor([0.9926]), 5: tensor([0.9926]), 6: tensor([0.9926]), 7: tensor([0.9926]), 8: tensor([0.9926]), 9: tensor([0.9926]), 10: tensor([0.9926]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.9926]), 14: tensor([0.9926]), 15: tensor([0.1607]), 16: tensor([0.9926]), 17: tensor([0.9926])}\n",
      "18\n",
      "3\n",
      "{2: {3: {0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{0: Linear(in_features=1, out_features=1, bias=False), 1: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 18: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "Species: 0 fitness: 6.7034837933810945 best fitness: 0.060810810810810814\n",
      "Species: 1 fitness: 6.527122735977173 best fitness: 4.5\n",
      "10\n",
      "Species: 0 fitness: 5.556499345280292 best fitness: 0.08411214953271028\n",
      "Species: 1 fitness: 6.681815125221431 best fitness: 0.20930232558139536\n",
      "11\n",
      "Species: 0 fitness: 5.6216708082671545 best fitness: 0.08256880733944955\n",
      "Species: 1 fitness: 8.714868906067641 best fitness: 0.21951219512195122\n",
      "12\n",
      "Species: 0 fitness: 5.592767312474879 best fitness: 0.09782608695652174\n",
      "Species: 1 fitness: 7.92373159836078 best fitness: 0.15517241379310345\n",
      "13\n",
      "Species: 0 fitness: 5.471665481726333 best fitness: 0.09375\n",
      "Species: 1 fitness: 8.092637516834122 best fitness: 0.16666666666666666\n",
      "14\n",
      "Species: 0 fitness: 5.957375837832073 best fitness: 0.09183673469387756\n",
      "Species: 1 fitness: 7.620767173858792 best fitness: 0.17307692307692307\n",
      "15\n",
      "Species: 0 fitness: 6.018180024239321 best fitness: 0.0967741935483871\n",
      "Species: 1 fitness: 8.48580473347714 best fitness: 0.15789473684210525\n",
      "16\n",
      "Species: 0 fitness: 5.784410398146681 best fitness: 0.10588235294117647\n",
      "Species: 1 fitness: 7.9341354058339135 best fitness: 0.13846153846153847\n",
      "17\n",
      "Species: 0 fitness: 5.477022671422296 best fitness: 0.10465116279069768\n",
      "Species: 1 fitness: 7.891776397824287 best fitness: 0.140625\n",
      "18\n",
      "Species: 0 fitness: 5.538531314367544 best fitness: 0.10344827586206896\n",
      "Species: 1 fitness: 8.544723868370063 best fitness: 0.14285714285714285\n",
      "19\n",
      "Species: 0 fitness: 5.455586301243831 best fitness: 0.09782608695652174\n",
      "Species: 1 fitness: 8.496541288392295 best fitness: 0.15517241379310345\n",
      "20\n",
      "Species: 0 fitness: 6.0671067804098096 best fitness: 0.1125\n",
      "Species: 1 fitness: 7.622443154879973 best fitness: 0.12857142857142856\n",
      "21\n",
      "Species: 0 fitness: 5.971139407452243 best fitness: 0.1111111111111111\n",
      "Species: 1 fitness: 7.669064784395516 best fitness: 0.13043478260869565\n",
      "22\n",
      "Species: 0 fitness: 5.978239760753961 best fitness: 0.09574468085106383\n",
      "Species: 1 fitness: 7.349193100418359 best fitness: 0.16071428571428573\n",
      "23\n",
      "Species: 0 fitness: 5.78090686642606 best fitness: 0.09782608695652174\n",
      "Species: 1 fitness: 8.18761218827346 best fitness: 0.15517241379310345\n",
      "24\n",
      "Species: 0 fitness: 5.996766356321477 best fitness: 0.0989010989010989\n",
      "Species: 1 fitness: 7.902507931499149 best fitness: 0.15254237288135594\n",
      "25\n",
      "Species: 0 fitness: 5.842475570989464 best fitness: 0.10112359550561797\n",
      "Species: 1 fitness: 7.954268544912344 best fitness: 0.15\n",
      "Species: 2 fitness: 1.0 best fitness: 1.0\n",
      "26\n",
      "Species: 0 fitness: 5.827610451498153 best fitness: 0.1111111111111111\n",
      "Species: 1 fitness: 8.134207006601194 best fitness: 0.13846153846153847\n",
      "Species: 2 fitness: 1.0 best fitness: 0.3333333333333333\n",
      "Species: 3 fitness: 9.0 best fitness: 9.0\n",
      "27\n",
      "Species: 0 fitness: 5.775131713019473 best fitness: 0.1\n",
      "Species: 1 fitness: 7.805002199976065 best fitness: 0.23684210526315788\n",
      "Species: 2 fitness: 2.2094267209370932 best fitness: 1.5427600542704265\n",
      "Species: 3 fitness: 8.592081471493369 best fitness: 0.47368421052631576\n",
      "28\n",
      "Species: 0 fitness: 5.640789118531639 best fitness: 0.1232876712328767\n",
      "Species: 1 fitness: 8.237066250098373 best fitness: 0.23684210526315788\n",
      "Species: 2 fitness: 3.028523392147488 best fitness: 0.9999996821085612\n",
      "Species: 3 fitness: 7.735114606221515 best fitness: 0.3\n",
      "29\n",
      "Species: 0 fitness: 5.178848602090559 best fitness: 0.12857142857142856\n",
      "Species: 1 fitness: 8.322769014458903 best fitness: 0.23684210526315788\n",
      "Species: 2 fitness: 6.098706566370451 best fitness: 0.6923076923076923\n",
      "Species: 3 fitness: 8.229546941559894 best fitness: 0.3103448275862069\n",
      "30\n",
      "Species: 0 fitness: 5.627339892387393 best fitness: 0.12\n",
      "Species: 2 fitness: 7.635681488297203 best fitness: 0.4090909090909091\n",
      "Species: 3 fitness: 7.684782831292404 best fitness: 0.47368421052631576\n",
      "Species: 4 fitness: 4.0 best fitness: 4.0\n",
      "31\n",
      "Species: 0 fitness: 5.363170725504562 best fitness: 0.12\n",
      "Species: 1 fitness: 7.433013788859047 best fitness: 0.3\n",
      "Species: 2 fitness: 8.827420300907558 best fitness: 0.25\n",
      "Species: 3 fitness: 3.9883545239766445 best fitness: 0.4444444444444444\n",
      "32\n",
      "Species: 0 fitness: 5.549151500550713 best fitness: 0.10975609756097561\n",
      "Species: 1 fitness: 7.666749048233031 best fitness: 0.3\n",
      "Species: 2 fitness: 8.590666697575495 best fitness: 0.34615384615384615\n",
      "Species: 3 fitness: 4.013339161872865 best fitness: 0.3466724952061971\n",
      "33\n",
      "Species: 0 fitness: 5.5890699414645875 best fitness: 0.1323529411764706\n",
      "Species: 1 fitness: 8.377045485708448 best fitness: 0.25\n",
      "Species: 2 fitness: 8.329685404896736 best fitness: 0.28125\n",
      "Species: 3 fitness: 4.009879827499389 best fitness: 0.29559329577854704\n",
      "34\n",
      "Species: 0 fitness: 6.284519966097847 best fitness: 0.13043478260869565\n",
      "Species: 1 fitness: 8.044670915603632 best fitness: 0.225\n",
      "Species: 2 fitness: 8.109175855463201 best fitness: 0.4090909090909091\n",
      "Species: 3 fitness: 5.002622278113114 best fitness: 0.4736441562050267\n",
      "35\n",
      "Species: 0 fitness: 5.839675327762961 best fitness: 0.140625\n",
      "Species: 1 fitness: 8.046979897731058 best fitness: 0.24324324324324326\n",
      "Species: 2 fitness: 7.927358252661567 best fitness: 0.32142857142857145\n",
      "Species: 3 fitness: 5.845839663555749 best fitness: 0.47367577803762334\n",
      "Species: 4 fitness: 6.50419020652771 best fitness: 4.5\n",
      "36\n",
      "Species: 0 fitness: 5.794175328879518 best fitness: 0.15517241379310345\n",
      "Species: 1 fitness: 7.070648687641796 best fitness: 0.21951219512195122\n",
      "Species: 2 fitness: 8.166756841871475 best fitness: 0.5\n",
      "Species: 3 fitness: 7.320171674092612 best fitness: 0.5\n",
      "Species: 4 fitness: 6.041523361206055 best fitness: 0.6\n",
      "37\n",
      "Species: 0 fitness: 5.799979000675437 best fitness: 0.1836734693877551\n",
      "Species: 1 fitness: 7.424223234487137 best fitness: 0.20930232558139536\n",
      "Species: 2 fitness: 7.90656680862109 best fitness: 0.375\n",
      "Species: 3 fitness: 6.263066732883454 best fitness: 0.45\n",
      "Species: 4 fitness: 6.965280107089451 best fitness: 0.6428571428571429\n",
      "38\n",
      "Species: 0 fitness: 5.927991502689867 best fitness: 0.16981132075471697\n",
      "Species: 1 fitness: 8.396880453283133 best fitness: 0.2727272727272727\n",
      "Species: 2 fitness: 7.710409316149626 best fitness: 0.4090909090909091\n",
      "Species: 3 fitness: 7.039037590935118 best fitness: 0.42857142857142855\n",
      "Species: 4 fitness: 7.997444450855256 best fitness: 0.45\n",
      "Species: 5 fitness: 9.0 best fitness: 9.0\n",
      "39\n",
      "Species: 0 fitness: 5.843448694362198 best fitness: 0.20930232558139536\n",
      "Species: 1 fitness: 8.055389546766516 best fitness: 0.21951219512195122\n",
      "Species: 2 fitness: 7.6841872867785 best fitness: 0.47368421052631576\n",
      "Species: 3 fitness: 7.157744206880269 best fitness: 0.47368421052631576\n",
      "Species: 4 fitness: 7.490967920848303 best fitness: 0.6428571428571429\n",
      "Species: 5 fitness: 9.000000000000002 best fitness: 0.6428571428571429\n",
      "40\n",
      "Species: 0 fitness: 5.211057641289449 best fitness: 0.2727272727272727\n",
      "Species: 1 fitness: 8.28816791736718 best fitness: 0.2727272727272727\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([0.]), 2: tensor([0.]), 3: tensor([0.]), 4: tensor([0.5000]), 5: tensor([0.9926]), 6: tensor([0.5000]), 7: tensor([0.5000]), 8: tensor([0.5000]), 9: tensor([0.5000]), 10: tensor([0.5000]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.5000]), 14: tensor([0.9926]), 15: tensor([0.9964]), 16: tensor([0.5000]), 17: tensor([0.5000]), 19: tensor([0.5000]), 20: tensor([5.5424e-06]), 21: tensor([0.5000]), 22: tensor([0.5000]), 23: tensor([0.9926]), 24: tensor([0.5000]), 25: tensor([0.5000]), 26: tensor([0.9926]), 27: tensor([0.5000]), 28: tensor([0.5000]), 29: tensor([0.9926]), 30: tensor([0.5000]), 31: tensor([0.9926]), 32: tensor([0.5000]), 33: tensor([1.0000]), 34: tensor([0.5000]), 35: tensor([0.5000]), 36: tensor([0.9926]), 37: tensor([0.5000]), 38: tensor([0.5000]), 39: tensor([0.5000]), 40: tensor([0.0107]), 41: tensor([0.5000]), 42: tensor([0.9926]), 43: tensor([0.5000]), 44: tensor([0.5000]), 45: tensor([0.9926]), 46: tensor([0.5000]), 47: tensor([0.5000]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([0.5000]), 51: tensor([0.5000]), 52: tensor([0.5000]), 53: tensor([0.9926]), 54: tensor([0.5000]), 56: tensor([0.5000]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.5000]), 59: tensor([0.5000]), 60: tensor([0.5000]), 62: tensor([0.5000]), 61: tensor([1.0000]), 63: tensor([0.5000]), 64: tensor([0.5000]), 65: tensor([0.9926]), 66: tensor([0.5000]), 67: tensor([0.5000]), 68: tensor([1.]), 69: tensor([0.9206]), 71: tensor([0.5000]), 70: tensor([0.5000]), 72: tensor([0.9964]), 73: tensor([0.5000]), 74: tensor([0.9206]), 75: tensor([0.5000]), 76: tensor([0.9926]), 78: tensor([0.5000]), 77: tensor([0.5000]), 79: tensor([0.5000]), 80: tensor([0.9926])}\n",
      "81\n",
      "3\n",
      "{4: {3: {0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}}, 1: {63: {1: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([1.]), 2: tensor([0.]), 3: tensor([1.]), 4: tensor([0.9926]), 5: tensor([0.9926]), 6: tensor([0.9926]), 7: tensor([0.5000]), 8: tensor([0.9926]), 9: tensor([0.9926]), 10: tensor([0.5000]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.5000]), 14: tensor([0.9926]), 15: tensor([0.9964]), 16: tensor([0.9926]), 17: tensor([0.9926]), 19: tensor([0.5000]), 20: tensor([5.5424e-06]), 21: tensor([0.9926]), 22: tensor([0.5000]), 23: tensor([0.9926]), 24: tensor([0.9926]), 25: tensor([0.5000]), 26: tensor([0.9926]), 27: tensor([0.9926]), 28: tensor([0.5000]), 29: tensor([0.9926]), 30: tensor([0.5000]), 31: tensor([0.9926]), 32: tensor([0.5000]), 33: tensor([1.0000]), 34: tensor([0.5000]), 35: tensor([0.9926]), 36: tensor([0.9926]), 37: tensor([0.9926]), 38: tensor([0.5000]), 39: tensor([0.9926]), 40: tensor([0.0107]), 41: tensor([0.5000]), 42: tensor([0.9926]), 43: tensor([0.5000]), 44: tensor([0.5000]), 45: tensor([0.9926]), 46: tensor([0.5000]), 47: tensor([0.9926]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([1.]), 51: tensor([0.9926]), 52: tensor([0.5000]), 53: tensor([0.9926]), 54: tensor([0.9926]), 56: tensor([0.5000]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.5000]), 59: tensor([0.9926]), 60: tensor([0.9926]), 62: tensor([0.5000]), 61: tensor([1.0000]), 63: tensor([1.]), 64: tensor([0.5000]), 65: tensor([0.9926]), 66: tensor([0.5000]), 67: tensor([0.9926]), 68: tensor([1.]), 69: tensor([0.9926]), 71: tensor([0.9926]), 70: tensor([0.5000]), 72: tensor([0.9964]), 73: tensor([0.9926]), 74: tensor([0.9926]), 75: tensor([0.9926]), 76: tensor([0.9926]), 78: tensor([0.5000]), 77: tensor([0.9926]), 79: tensor([0.9926]), 80: tensor([0.9926])}\n",
      "81\n",
      "3\n",
      "{4: {3: {0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}}, 1: {63: {1: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([0.]), 2: tensor([1.]), 3: tensor([1.]), 4: tensor([0.5000]), 5: tensor([0.9926]), 6: tensor([0.5000]), 7: tensor([0.9926]), 8: tensor([0.5000]), 9: tensor([0.5000]), 10: tensor([0.9926]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.9926]), 14: tensor([0.9926]), 15: tensor([1.0000]), 16: tensor([0.5000]), 17: tensor([0.5000]), 19: tensor([0.9926]), 20: tensor([5.5424e-06]), 21: tensor([0.5000]), 22: tensor([0.9926]), 23: tensor([0.9926]), 24: tensor([0.5000]), 25: tensor([0.9926]), 26: tensor([0.9926]), 27: tensor([0.5000]), 28: tensor([0.9926]), 29: tensor([0.9926]), 30: tensor([0.9926]), 31: tensor([0.9926]), 32: tensor([0.9926]), 33: tensor([1.0000]), 34: tensor([0.1965]), 35: tensor([0.5000]), 36: tensor([0.9926]), 37: tensor([0.5000]), 38: tensor([0.9926]), 39: tensor([0.5000]), 40: tensor([0.0107]), 41: tensor([0.9926]), 42: tensor([0.9926]), 43: tensor([0.9926]), 44: tensor([0.9926]), 45: tensor([0.9926]), 46: tensor([0.9926]), 47: tensor([0.5000]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([0.5000]), 51: tensor([0.5000]), 52: tensor([0.9926]), 53: tensor([0.9926]), 54: tensor([0.5000]), 56: tensor([0.9926]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.9926]), 59: tensor([0.5000]), 60: tensor([0.5000]), 62: tensor([0.9926]), 61: tensor([1.0000]), 63: tensor([0.5000]), 64: tensor([0.9926]), 65: tensor([0.9926]), 66: tensor([1.0000]), 67: tensor([0.5000]), 68: tensor([1.]), 69: tensor([0.9206]), 71: tensor([0.5000]), 70: tensor([0.9926]), 72: tensor([0.9964]), 73: tensor([0.5000]), 74: tensor([0.9206]), 75: tensor([0.5000]), 76: tensor([0.9926]), 78: tensor([0.9926]), 77: tensor([0.5000]), 79: tensor([0.5000]), 80: tensor([0.9926])}\n",
      "81\n",
      "3\n",
      "{4: {3: {0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}}, 1: {63: {1: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([1.]), 2: tensor([1.]), 3: tensor([1.]), 4: tensor([0.9926]), 5: tensor([0.9926]), 6: tensor([0.9926]), 7: tensor([0.9926]), 8: tensor([0.9926]), 9: tensor([0.9926]), 10: tensor([0.9926]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.9926]), 14: tensor([0.9926]), 15: tensor([1.0000]), 16: tensor([0.9926]), 17: tensor([0.9926]), 19: tensor([0.9926]), 20: tensor([5.5424e-06]), 21: tensor([0.9926]), 22: tensor([0.9926]), 23: tensor([0.9926]), 24: tensor([0.9926]), 25: tensor([0.9926]), 26: tensor([0.9926]), 27: tensor([0.9926]), 28: tensor([0.9926]), 29: tensor([0.9926]), 30: tensor([0.9926]), 31: tensor([0.9926]), 32: tensor([0.9926]), 33: tensor([1.0000]), 34: tensor([0.1965]), 35: tensor([0.9926]), 36: tensor([0.9926]), 37: tensor([0.9926]), 38: tensor([0.9926]), 39: tensor([0.9926]), 40: tensor([0.0107]), 41: tensor([0.9926]), 42: tensor([0.9926]), 43: tensor([0.9926]), 44: tensor([0.9926]), 45: tensor([0.9926]), 46: tensor([0.9926]), 47: tensor([0.9926]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([1.]), 51: tensor([0.9926]), 52: tensor([0.9926]), 53: tensor([0.9926]), 54: tensor([0.9926]), 56: tensor([0.9926]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.9926]), 59: tensor([0.9926]), 60: tensor([0.9926]), 62: tensor([0.9926]), 61: tensor([1.0000]), 63: tensor([1.]), 64: tensor([0.9926]), 65: tensor([0.9926]), 66: tensor([1.0000]), 67: tensor([0.9926]), 68: tensor([1.]), 69: tensor([0.9926]), 71: tensor([0.9926]), 70: tensor([0.9926]), 72: tensor([0.9964]), 73: tensor([0.9926]), 74: tensor([0.9926]), 75: tensor([0.9926]), 76: tensor([0.9926]), 78: tensor([0.9926]), 77: tensor([0.9926]), 79: tensor([0.9926]), 80: tensor([0.9926])}\n",
      "81\n",
      "3\n",
      "{4: {3: {0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}}, 1: {63: {1: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{0: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False), 81: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "Species: 2 fitness: 7.29454008432535 best fitness: 0.34615384615384615\n",
      "Species: 3 fitness: 5.365488897670398 best fitness: 0.4090909090909091\n",
      "Species: 4 fitness: 7.015634560585023 best fitness: 0.45\n",
      "Species: 5 fitness: 9.0 best fitness: 0.5625\n",
      "41\n",
      "Species: 0 fitness: 5.31760035423522 best fitness: 0.19148936170212766\n",
      "Species: 1 fitness: 7.867895688329424 best fitness: 0.32142857142857145\n",
      "Species: 2 fitness: 6.0886409997940065 best fitness: 0.45\n",
      "Species: 3 fitness: 5.8514712417826935 best fitness: 0.5294117647058824\n",
      "Species: 4 fitness: 6.881549231211344 best fitness: 0.6\n",
      "Species: 5 fitness: 9.000000000000002 best fitness: 0.391304347826087\n",
      "42\n",
      "Species: 0 fitness: 5.543294095993041 best fitness: 0.225\n",
      "Species: 1 fitness: 6.998668236117207 best fitness: 0.2903225806451613\n",
      "Species: 2 fitness: 7.534178313087015 best fitness: 0.5294117647058824\n",
      "Species: 3 fitness: 6.973450225332508 best fitness: 0.391304347826087\n",
      "Species: 4 fitness: 6.662313961982728 best fitness: 0.45\n",
      "Species: 5 fitness: 8.161587746519793 best fitness: 0.47368421052631576\n",
      "43\n",
      "Species: 0 fitness: 5.929698146714104 best fitness: 0.2\n",
      "Species: 1 fitness: 8.246571248577485 best fitness: 0.2903225806451613\n",
      "Species: 2 fitness: 7.788434152801831 best fitness: 0.375\n",
      "Species: 3 fitness: 5.5479979664087296 best fitness: 0.5625\n",
      "Species: 4 fitness: 8.230769230769232 best fitness: 0.6923076923076923\n",
      "Species: 5 fitness: 8.978660131755626 best fitness: 0.47368421052631576\n",
      "Species: 6 fitness: 6.513104438781738 best fitness: 4.499998569488525\n",
      "44\n",
      "Species: 0 fitness: 6.115105754799313 best fitness: 0.25\n",
      "Species: 1 fitness: 7.66002993924277 best fitness: 0.32142857142857145\n",
      "Species: 2 fitness: 6.964279109034049 best fitness: 0.3103448275862069\n",
      "Species: 3 fitness: 6.589721826406625 best fitness: 0.6923076923076923\n",
      "Species: 4 fitness: 7.529411764705882 best fitness: 0.5294117647058824\n",
      "Species: 5 fitness: 8.999937216440838 best fitness: 0.5\n",
      "Species: 6 fitness: 5.661591370900472 best fitness: 1.0\n",
      "45\n",
      "Species: 0 fitness: 5.1319909516502795 best fitness: 0.2647058823529412\n",
      "Species: 1 fitness: 8.56042383511861 best fitness: 0.3\n",
      "Species: 2 fitness: 7.486285110999803 best fitness: 0.3103448275862069\n",
      "Species: 3 fitness: 7.330131159888374 best fitness: 0.5\n",
      "Species: 4 fitness: 6.811574041843414 best fitness: 0.5625\n",
      "Species: 5 fitness: 8.449325834001815 best fitness: 0.6428571428571429\n",
      "Species: 6 fitness: 8.349303245544434 best fitness: 1.125\n",
      "Species: 7 fitness: 4.0 best fitness: 4.0\n",
      "46\n",
      "Species: 0 fitness: 5.922824525833133 best fitness: 0.3\n",
      "Species: 1 fitness: 7.358586359024047 best fitness: 0.3\n",
      "Species: 2 fitness: 7.014474244117739 best fitness: 0.36\n",
      "Species: 3 fitness: 6.334239707273595 best fitness: 0.5294117647058824\n",
      "Species: 4 fitness: 6.119389468973332 best fitness: 0.8181818181818182\n",
      "Species: 5 fitness: 8.905888523374287 best fitness: 0.6428571428571429\n",
      "Species: 6 fitness: 7.821954449017842 best fitness: 0.5\n",
      "Species: 7 fitness: 4.0 best fitness: 0.8\n",
      "47\n",
      "Species: 0 fitness: 4.840526621917199 best fitness: 0.3103448275862069\n",
      "Species: 1 fitness: 7.962526284731348 best fitness: 0.34615384615384615\n",
      "Species: 3 fitness: 7.096308968283913 best fitness: 0.4090909090909091\n",
      "Species: 4 fitness: 6.777777724795872 best fitness: 0.5\n",
      "Species: 5 fitness: 8.950939785350453 best fitness: 0.8181818181818182\n",
      "Species: 6 fitness: 6.949993401765823 best fitness: 0.5625\n",
      "Species: 7 fitness: 3.999998092651367 best fitness: 2.0\n",
      "48\n",
      "Species: 0 fitness: 5.504742295401433 best fitness: 0.2571428571428571\n",
      "Species: 2 fitness: 7.027759655662205 best fitness: 0.391304347826087\n",
      "Species: 3 fitness: 6.367142066955568 best fitness: 0.36\n",
      "Species: 4 fitness: 8.306692759195965 best fitness: 0.5\n",
      "Species: 5 fitness: 7.768360078334808 best fitness: 0.5625\n",
      "Species: 6 fitness: 3.7058832645416255 best fitness: 0.6666666666666666\n",
      "Species: 7 fitness: 4.0 best fitness: 4.0\n",
      "49\n",
      "Species: 0 fitness: 5.692697484152654 best fitness: 0.2571428571428571\n",
      "Species: 1 fitness: 6.610550075769424 best fitness: 0.28125\n",
      "Species: 2 fitness: 5.893057695456917 best fitness: 0.32142857142857145\n",
      "Species: 3 fitness: 8.171662557692756 best fitness: 0.42857142857142855\n",
      "Species: 4 fitness: 7.950118215460527 best fitness: 0.47368421052631576\n",
      "Species: 5 fitness: 4.0 best fitness: 0.5\n",
      "Species: 6 fitness: 5.0413265228271475 best fitness: 1.2706187111990792\n",
      "50\n",
      "Species: 0 fitness: 5.3052998845641675 best fitness: 0.24324324324324326\n",
      "Species: 1 fitness: 6.632159741719567 best fitness: 0.3\n",
      "Species: 2 fitness: 5.691061225430721 best fitness: 0.3103448275862069\n",
      "Species: 3 fitness: 8.011065751314163 best fitness: 0.5625\n",
      "Species: 4 fitness: 8.078580012688269 best fitness: 0.34615384615384615\n",
      "Species: 5 fitness: 4.0 best fitness: 1.0\n",
      "Species: 6 fitness: 7.76528000831604 best fitness: 1.124969244003296\n",
      "51\n",
      "Species: 0 fitness: 5.779944524168966 best fitness: 0.225\n",
      "Species: 2 fitness: 6.4364454642586075 best fitness: 0.391304347826087\n",
      "Species: 3 fitness: 8.406933868632597 best fitness: 0.5294117647058824\n",
      "Species: 4 fitness: 7.862698858434503 best fitness: 0.4090909090909091\n",
      "Species: 5 fitness: 3.9999999999999996 best fitness: 0.6666666666666666\n",
      "Species: 6 fitness: 6.139219011579242 best fitness: 0.6428571428571429\n",
      "52\n",
      "Species: 0 fitness: 6.190193760685808 best fitness: 0.21951219512195122\n",
      "Species: 1 fitness: 7.196275334204396 best fitness: 0.2903225806451613\n",
      "Species: 2 fitness: 7.807069454193115 best fitness: 0.36\n",
      "Species: 3 fitness: 7.569486661390824 best fitness: 0.4090909090909091\n",
      "Species: 4 fitness: 3.9999999999999996 best fitness: 0.4\n",
      "Species: 5 fitness: 6.248910699571882 best fitness: 0.42857142857142855\n",
      "53\n",
      "Species: 0 fitness: 5.592236679653792 best fitness: 0.20930232558139536\n",
      "Species: 1 fitness: 7.321160640716555 best fitness: 0.36\n",
      "Species: 2 fitness: 8.72514202378013 best fitness: 0.4090909090909091\n",
      "Species: 3 fitness: 7.265926003456117 best fitness: 0.375\n",
      "Species: 4 fitness: 3.9999999999999987 best fitness: 0.2857142857142857\n",
      "Species: 5 fitness: 6.449082417921587 best fitness: 0.4090909090909091\n",
      "54\n",
      "Species: 0 fitness: 4.360932520457678 best fitness: 0.1836734693877551\n",
      "Species: 1 fitness: 6.741535695393881 best fitness: 0.3\n",
      "Species: 2 fitness: 7.503835958593031 best fitness: 0.5294117647058824\n",
      "Species: 3 fitness: 7.810744285583499 best fitness: 0.45\n",
      "Species: 4 fitness: 3.999999999999999 best fitness: 0.5714285714285714\n",
      "Species: 5 fitness: 6.782759719424776 best fitness: 0.3333333333333333\n",
      "55\n",
      "Species: 0 fitness: 4.867971444129943 best fitness: 0.225\n",
      "Species: 1 fitness: 6.502013291631428 best fitness: 0.32142857142857145\n",
      "Species: 2 fitness: 7.465834917845548 best fitness: 0.3333333333333333\n",
      "Species: 3 fitness: 6.890908684049335 best fitness: 0.32142857142857145\n",
      "Species: 4 fitness: 4.0 best fitness: 0.8\n",
      "Species: 5 fitness: 7.380956967671714 best fitness: 0.42857142857142855\n",
      "Species: 6 fitness: 9.0 best fitness: 9.0\n",
      "56\n",
      "Species: 0 fitness: 4.683949205610488 best fitness: 0.25\n",
      "Species: 2 fitness: 8.769420237768266 best fitness: 0.42857142857142855\n",
      "Species: 3 fitness: 6.246248022715253 best fitness: 0.3\n",
      "Species: 4 fitness: 4.0 best fitness: 1.0\n",
      "Species: 5 fitness: 7.013079743636282 best fitness: 0.47368421052631576\n",
      "Species: 6 fitness: 8.642858028411867 best fitness: 0.6428571428571429\n",
      "57\n",
      "Species: 0 fitness: 4.623686223030092 best fitness: 0.18\n",
      "Species: 1 fitness: 7.882021614483422 best fitness: 0.32142857142857145\n",
      "Species: 2 fitness: 7.312339388805888 best fitness: 0.391304347826087\n",
      "Species: 3 fitness: 4.45454519445246 best fitness: 0.8181815580888228\n",
      "Species: 4 fitness: 6.666666666666665 best fitness: 0.6\n",
      "Species: 5 fitness: 8.663043478260871 best fitness: 0.391304347826087\n",
      "58\n",
      "Species: 0 fitness: 5.340980789240666 best fitness: 0.2647058823529412\n",
      "Species: 1 fitness: 7.7569527449431215 best fitness: 0.3333333333333333\n",
      "Species: 2 fitness: 7.563783387880066 best fitness: 0.24324324324324326\n",
      "Species: 3 fitness: 4.7831333705357135 best fitness: 0.6428571428571429\n",
      "Species: 4 fitness: 7.1559780120849625 best fitness: 0.45\n",
      "Species: 5 fitness: 8.687930762767792 best fitness: 0.5625\n",
      "Species: 6 fitness: 4.0 best fitness: 2.0\n",
      "59\n",
      "Species: 0 fitness: 5.188343391698949 best fitness: 0.17647058823529413\n",
      "Species: 2 fitness: 7.203379090627034 best fitness: 0.3\n",
      "Species: 3 fitness: 7.748966693878174 best fitness: 1.125\n",
      "Species: 4 fitness: 7.177371422449748 best fitness: 0.375\n",
      "Species: 5 fitness: 8.1631262699763 best fitness: 0.75\n",
      "Species: 6 fitness: 4.9427833557128915 best fitness: 0.8947933197021485\n",
      "60\n",
      "Species: 0 fitness: 5.62098168217859 best fitness: 0.20930232558139536\n",
      "Species: 1 fitness: 6.804589569568635 best fitness: 0.375\n",
      "Species: 2 fitness: 5.634536898654439 best fitness: 0.391304347826087\n",
      "Species: 3 fitness: 7.266155927077583 best fitness: 0.391304347826087\n",
      "Species: 4 fitness: 7.619142575697466 best fitness: 0.4090909090909091\n",
      "Species: 5 fitness: 5.949089908599853 best fitness: 0.6\n",
      "61\n",
      "Species: 0 fitness: 5.269677422263404 best fitness: 0.2727272727272727\n",
      "Species: 1 fitness: 6.684639501571656 best fitness: 0.3\n",
      "Species: 2 fitness: 6.70516397213114 best fitness: 0.3103448275862069\n",
      "Species: 3 fitness: 8.126682897408804 best fitness: 0.375\n",
      "Species: 4 fitness: 7.888888888888889 best fitness: 0.5\n",
      "Species: 5 fitness: 6.625004209578037 best fitness: 0.5625\n",
      "62\n",
      "Species: 0 fitness: 4.69857775842821 best fitness: 0.24324324324324326\n",
      "Species: 1 fitness: 7.134052491188052 best fitness: 0.45\n",
      "Species: 2 fitness: 7.173563611918485 best fitness: 0.3103448275862069\n",
      "Species: 3 fitness: 7.807991559688861 best fitness: 0.34615384615384615\n",
      "Species: 4 fitness: 8.126767179240352 best fitness: 0.391304347826087\n",
      "Species: 5 fitness: 7.571428571428573 best fitness: 0.6428571428571429\n",
      "Species: 6 fitness: 4.0 best fitness: 4.0\n",
      "63\n",
      "Species: 0 fitness: 5.652270903458465 best fitness: 0.24324324324324326\n",
      "Species: 1 fitness: 8.000131773948672 best fitness: 0.45\n",
      "Species: 2 fitness: 5.124975038611371 best fitness: 0.391304347826087\n",
      "Species: 3 fitness: 7.5430449572476475 best fitness: 0.4090909090909091\n",
      "Species: 4 fitness: 8.743871688842775 best fitness: 0.45\n",
      "Species: 5 fitness: 6.0466983318328875 best fitness: 0.375\n",
      "Species: 6 fitness: 4.0 best fitness: 1.0\n",
      "64\n",
      "Species: 0 fitness: 4.838694193146443 best fitness: 0.20454545454545456\n",
      "Species: 2 fitness: 7.143245624459308 best fitness: 0.391304347826087\n",
      "Species: 3 fitness: 8.124923680957997 best fitness: 0.47368421052631576\n",
      "Species: 4 fitness: 8.552182626724246 best fitness: 0.45\n",
      "Species: 5 fitness: 6.499908745288849 best fitness: 0.5625\n",
      "Species: 6 fitness: 3.9999999999999996 best fitness: 0.6666666666666666\n",
      "65\n",
      "Species: 0 fitness: 5.060621658960978 best fitness: 0.17647058823529413\n",
      "Species: 1 fitness: 5.946181629643292 best fitness: 0.2727272727272727\n",
      "Species: 2 fitness: 7.378148013895208 best fitness: 0.4090909090909091\n",
      "Species: 3 fitness: 8.437995553016663 best fitness: 0.375\n",
      "Species: 4 fitness: 5.538441511300893 best fitness: 0.6923076923076923\n",
      "Species: 5 fitness: 3.9999999999999996 best fitness: 0.6666666666666666\n",
      "Species: 6 fitness: 4.0004377365112305 best fitness: 4.0004377365112305\n",
      "66\n",
      "Species: 0 fitness: 5.337971084458483 best fitness: 0.2571428571428571\n",
      "Species: 2 fitness: 8.033167600631712 best fitness: 0.34615384615384615\n",
      "Species: 3 fitness: 7.084785475450402 best fitness: 0.2647058823529412\n",
      "Species: 4 fitness: 6.327481530606747 best fitness: 0.5625\n",
      "Species: 5 fitness: 4.000000000000001 best fitness: 0.4444444444444444\n",
      "Species: 6 fitness: 3.9750778277715044 best fitness: 0.6666666666666666\n",
      "67\n",
      "Species: 0 fitness: 5.604534559133579 best fitness: 0.21951219512195122\n",
      "Species: 1 fitness: 7.702229111282913 best fitness: 0.3333333333333333\n",
      "Species: 2 fitness: 7.866832733154296 best fitness: 0.391304347826087\n",
      "Species: 3 fitness: 6.022985795448569 best fitness: 0.3103448275862069\n",
      "Species: 4 fitness: 4.0158039161137165 best fitness: 0.3015235151563372\n",
      "Species: 5 fitness: 3.7876754283905023 best fitness: 0.2666894276936849\n",
      "Species: 6 fitness: 4.0 best fitness: 4.0\n",
      "68\n",
      "Species: 1 fitness: 7.668114318847657 best fitness: 0.36\n",
      "Species: 2 fitness: 6.978427982330324 best fitness: 0.36\n",
      "Species: 3 fitness: 6.132598059517997 best fitness: 0.42857142857142855\n",
      "Species: 4 fitness: 4.666237183979579 best fitness: 0.6220461981637138\n",
      "Species: 5 fitness: 3.9999994550432474 best fitness: 0.5714285714285714\n",
      "Species: 6 fitness: 4.0 best fitness: 2.0\n",
      "69\n",
      "Species: 1 fitness: 8.171992797117964 best fitness: 0.34615384615384615\n",
      "Species: 2 fitness: 6.4896979179137775 best fitness: 0.23076923076923078\n",
      "Species: 3 fitness: 4.437678856008193 best fitness: 0.497070592992446\n",
      "Species: 4 fitness: 3.9844025303335755 best fitness: 0.23529411764705882\n",
      "Species: 5 fitness: 3.9999999999999996 best fitness: 0.26666666666666666\n",
      "Species: 6 fitness: 4.385469277699789 best fitness: 1.0518548488616943\n",
      "70\n",
      "Species: 0 fitness: 8.312772820977605 best fitness: 0.2647058823529412\n",
      "Species: 1 fitness: 6.1564476897842 best fitness: 0.23684210526315788\n",
      "Species: 2 fitness: 4.4364697270923195 best fitness: 0.4626051055060493\n",
      "Species: 3 fitness: 3.7217926846610183 best fitness: 0.25089142057630753\n",
      "Species: 4 fitness: 3.9621967633565265 best fitness: 0.26666666666666666\n",
      "Species: 5 fitness: 4.3230346750330035 best fitness: 0.3318214769716616\n",
      "71\n",
      "Species: 0 fitness: 7.6505437358733115 best fitness: 0.2903225806451613\n",
      "Species: 1 fitness: 5.700215775792194 best fitness: 0.21951219512195122\n",
      "Species: 2 fitness: 4.503584533929825 best fitness: 0.48526328802108765\n",
      "Species: 3 fitness: 3.7668975700031635 best fitness: 0.36363636363636365\n",
      "Species: 4 fitness: 4.436865166613928 best fitness: 0.47286118959125717\n",
      "Species: 5 fitness: 4.908231429755688 best fitness: 0.27668482065200806\n",
      "72\n",
      "Species: 0 fitness: 7.225158819785484 best fitness: 0.34615384615384615\n",
      "Species: 1 fitness: 5.682361096143721 best fitness: 0.20454545454545456\n",
      "Species: 2 fitness: 4.692305485407512 best fitness: 0.42852342696416945\n",
      "Species: 3 fitness: 3.2484042048454285 best fitness: 0.3333333333333333\n",
      "Species: 4 fitness: 5.66259195302662 best fitness: 0.47368421052631576\n",
      "Species: 5 fitness: 5.359849069799696 best fitness: 0.3213907650538853\n",
      "73\n",
      "Species: 0 fitness: 8.310344432962356 best fitness: 0.3103448275862069\n",
      "Species: 1 fitness: 6.1596071358883 best fitness: 0.2727272727272727\n",
      "Species: 2 fitness: 4.812793996598986 best fitness: 0.49991443422105575\n",
      "Species: 3 fitness: 3.987813387598309 best fitness: 0.2857142857142857\n",
      "Species: 4 fitness: 5.663682179017499 best fitness: 0.4090909090909091\n",
      "Species: 5 fitness: 4.786681988660025 best fitness: 0.2641400449416217\n",
      "74\n",
      "Species: 0 fitness: 7.3966929335747995 best fitness: 0.2903225806451613\n",
      "Species: 1 fitness: 6.680427683724294 best fitness: 0.25\n",
      "Species: 2 fitness: 4.990511460737748 best fitness: 0.40908787467262964\n",
      "Species: 3 fitness: 3.7906308695673943 best fitness: 0.25\n",
      "Species: 4 fitness: 7.1480639321463455 best fitness: 0.6428571428571429\n",
      "Species: 5 fitness: 5.060932667024672 best fitness: 0.2903102136427356\n",
      "75\n",
      "Species: 0 fitness: 7.302190462748208 best fitness: 0.3333333333333333\n",
      "Species: 1 fitness: 5.733126871513597 best fitness: 0.2727272727272727\n",
      "Species: 2 fitness: 5.201250579622057 best fitness: 0.4999956554836697\n",
      "Species: 3 fitness: 4.000000000000001 best fitness: 0.4444444444444444\n",
      "Species: 4 fitness: 6.643945770263673 best fitness: 0.36\n",
      "Species: 5 fitness: 4.940705449957596 best fitness: 0.23683713611803556\n",
      "76\n",
      "Species: 1 fitness: 6.4605691350739605 best fitness: 0.3103448275862069\n",
      "Species: 2 fitness: 3.931071942502802 best fitness: 0.3351938941261985\n",
      "Species: 3 fitness: 3.8000315984090163 best fitness: 0.26666666666666666\n",
      "Species: 4 fitness: 6.498752236366272 best fitness: 0.32142857142857145\n",
      "Species: 5 fitness: 5.2984328116140045 best fitness: 0.2903225806451613\n",
      "77\n",
      "Species: 0 fitness: 7.351279023289676 best fitness: 0.225\n",
      "Species: 1 fitness: 5.306555617939342 best fitness: 0.40905592658303\n",
      "Species: 2 fitness: 3.999999091738748 best fitness: 0.19047619047619047\n",
      "Species: 3 fitness: 6.610785766884131 best fitness: 0.3333333333333333\n",
      "Species: 4 fitness: 5.5845065265893945 best fitness: 0.225\n",
      "78\n",
      "Species: 0 fitness: 6.300568091869351 best fitness: 0.225\n",
      "Species: 1 fitness: 5.849678880289981 best fitness: 0.4736798437018144\n",
      "Species: 2 fitness: 4.155288429821239 best fitness: 0.5164555381326115\n",
      "Species: 3 fitness: 7.119357413715784 best fitness: 0.25\n",
      "Species: 4 fitness: 5.664092217621049 best fitness: 0.23684210526315788\n",
      "79\n",
      "Species: 1 fitness: 5.073741282186201 best fitness: 0.2903225806451613\n",
      "Species: 2 fitness: 5.510332182834022 best fitness: 0.47367698267886515\n",
      "Species: 3 fitness: 6.375612862904867 best fitness: 0.3\n",
      "Species: 4 fitness: 6.20216992843983 best fitness: 0.20930232558139536\n",
      "80\n",
      "Species: 0 fitness: 6.114078609148663 best fitness: 0.3\n",
      "Species: 1 fitness: 6.964045242027001 best fitness: 0.3333331920482494\n",
      "Species: 2 fitness: 6.759564093921501 best fitness: 0.1956521739130435\n",
      "Species: 3 fitness: 6.343522992539912 best fitness: 0.19148936170212766\n",
      "81\n",
      "Species: 0 fitness: 6.125874735414982 best fitness: 0.28125\n",
      "Species: 1 fitness: 7.444811306501688 best fitness: 0.23684210526315788\n",
      "Species: 2 fitness: 6.096471954614688 best fitness: 0.23076923076923078\n",
      "Species: 3 fitness: 6.2909415423870065 best fitness: 0.225\n",
      "Species: 4 fitness: 9.0 best fitness: 9.0\n",
      "82\n",
      "Species: 0 fitness: 5.491400643398887 best fitness: 0.47368421052631576\n",
      "Species: 1 fitness: 7.461994809763773 best fitness: 0.32142857142857145\n",
      "Species: 2 fitness: 6.301408674981856 best fitness: 0.3333333333333333\n",
      "Species: 3 fitness: 5.888921819749426 best fitness: 0.14754098360655737\n",
      "Species: 4 fitness: 7.928571224212648 best fitness: 0.6428571428571429\n",
      "Species: 5 fitness: 4.0 best fitness: 4.0\n",
      "83\n",
      "Species: 1 fitness: 7.487323088305336 best fitness: 0.32142857142857145\n",
      "Species: 2 fitness: 6.516010765371653 best fitness: 0.3103448275862069\n",
      "Species: 3 fitness: 6.01766724679984 best fitness: 0.17647058823529413\n",
      "Species: 4 fitness: 7.927968706403461 best fitness: 0.6428571428571429\n",
      "Species: 5 fitness: 4.000000000000001 best fitness: 0.36363636363636365\n",
      "84\n",
      "Species: 0 fitness: 7.877327497800191 best fitness: 0.3\n",
      "Species: 1 fitness: 6.354638688704545 best fitness: 0.2647058823529412\n",
      "Species: 2 fitness: 5.85969125813451 best fitness: 0.15517241379310345\n",
      "Species: 3 fitness: 7.497335100173951 best fitness: 0.45\n",
      "Species: 4 fitness: 4.0 best fitness: 0.5\n",
      "85\n",
      "Species: 0 fitness: 8.092731684446335 best fitness: 0.28125\n",
      "Species: 1 fitness: 6.2614448351018535 best fitness: 0.2647058823529412\n",
      "Species: 2 fitness: 5.738041162490841 best fitness: 0.16363636363636364\n",
      "Species: 3 fitness: 7.156545852359973 best fitness: 0.47368421052631576\n",
      "Species: 4 fitness: 4.000130081176757 best fitness: 0.4001300811767578\n",
      "86\n",
      "Species: 1 fitness: 6.417395823710672 best fitness: 0.24324324324324326\n",
      "Species: 2 fitness: 5.455532963682967 best fitness: 0.21951219512195122\n",
      "Species: 3 fitness: 7.409090909090909 best fitness: 0.4090909090909091\n",
      "Species: 4 fitness: 3.99998688697815 best fitness: 0.3333335717519124\n",
      "87\n",
      "Species: 0 fitness: 5.958512318439971 best fitness: 0.23076923076923078\n",
      "Species: 1 fitness: 5.845128087855099 best fitness: 0.13432835820895522\n",
      "Species: 2 fitness: 7.797811241149905 best fitness: 0.36\n",
      "Species: 3 fitness: 3.8402183244102863 best fitness: 0.21053299150968852\n",
      "88\n",
      "Species: 1 fitness: 6.068501299825206 best fitness: 0.15517241379310345\n",
      "Species: 2 fitness: 6.802842944860458 best fitness: 0.28125\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([0.]), 2: tensor([0.]), 3: tensor([2.0567e-17]), 4: tensor([0.5000]), 5: tensor([0.9926]), 6: tensor([0.5000]), 7: tensor([0.5000]), 8: tensor([0.5000]), 9: tensor([0.5000]), 10: tensor([0.5000]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.5000]), 14: tensor([0.9926]), 15: tensor([0.9964]), 16: tensor([0.5000]), 17: tensor([0.5000]), 19: tensor([0.5000]), 20: tensor([5.5424e-06]), 21: tensor([0.5000]), 22: tensor([0.5000]), 23: tensor([0.9926]), 24: tensor([0.5000]), 25: tensor([0.5000]), 26: tensor([0.9926]), 27: tensor([0.5000]), 28: tensor([0.5000]), 29: tensor([0.9926]), 30: tensor([0.5000]), 31: tensor([0.9926]), 32: tensor([0.5000]), 33: tensor([1.0000]), 34: tensor([0.5000]), 35: tensor([0.5000]), 36: tensor([0.9926]), 37: tensor([0.5000]), 38: tensor([0.5000]), 39: tensor([0.5000]), 40: tensor([0.0107]), 41: tensor([0.5000]), 42: tensor([0.9926]), 43: tensor([0.5000]), 44: tensor([0.5000]), 45: tensor([0.9926]), 46: tensor([0.5000]), 47: tensor([0.5000]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([0.5000]), 51: tensor([0.5000]), 52: tensor([0.5000]), 53: tensor([0.9926]), 54: tensor([0.5000]), 56: tensor([0.5000]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.5000]), 59: tensor([0.5000]), 60: tensor([0.5000]), 62: tensor([0.5000]), 61: tensor([1.0000]), 63: tensor([0.9967]), 64: tensor([0.5000]), 65: tensor([0.9926]), 66: tensor([0.5000]), 67: tensor([0.5000]), 68: tensor([1.]), 69: tensor([0.9206]), 71: tensor([0.5000]), 70: tensor([0.5000]), 72: tensor([0.9964]), 73: tensor([0.5000]), 74: tensor([0.9206]), 75: tensor([0.5000]), 76: tensor([0.9926]), 78: tensor([0.5000]), 77: tensor([0.5000]), 79: tensor([0.5000]), 80: tensor([0.9926]), 82: tensor([0.9206]), 83: tensor([0.5000]), 84: tensor([0.9926]), 85: tensor([0.5000]), 86: tensor([0.9926]), 88: tensor([0.5000]), 87: tensor([0.5000]), 89: tensor([0.5000]), 91: tensor([0.5000]), 90: tensor([0.5000]), 92: tensor([1.0000]), 93: tensor([0.5000]), 94: tensor([0.5000]), 95: tensor([0.9926]), 96: tensor([0.9206]), 97: tensor([0.9926]), 99: tensor([0.5000]), 98: tensor([0.9926]), 100: tensor([0.5000]), 102: tensor([2.4260e-08]), 101: tensor([0.5000]), 103: tensor([0.9926]), 104: tensor([0.2192]), 105: tensor([0.5000]), 106: tensor([0.5000]), 107: tensor([0.9926]), 109: tensor([0.9926]), 108: tensor([0.5000]), 110: tensor([0.5000]), 111: tensor([0.9926]), 112: tensor([0.5000]), 113: tensor([0.5000]), 114: tensor([0.9926]), 115: tensor([0.9926]), 116: tensor([0.5000]), 117: tensor([0.9926]), 118: tensor([0.5000]), 120: tensor([0.5000]), 119: tensor([0.9926]), 121: tensor([0.9926]), 122: tensor([0.5000]), 123: tensor([0.9926]), 124: tensor([0.5008]), 125: tensor([0.5000]), 126: tensor([0.5000]), 127: tensor([0.9926]), 128: tensor([0.5001]), 129: tensor([0.9926]), 130: tensor([0.5000]), 131: tensor([0.9926]), 132: tensor([0.5000]), 133: tensor([0.5000]), 134: tensor([0.5000]), 135: tensor([0.5000]), 136: tensor([0.5000]), 138: tensor([0.5000]), 137: tensor([0.9926]), 139: tensor([0.5000]), 140: tensor([0.9813]), 141: tensor([0.5000]), 142: tensor([0.5000]), 143: tensor([8.9021e-09]), 144: tensor([0.9206]), 145: tensor([0.5000]), 146: tensor([0.9206]), 147: tensor([0.5000]), 148: tensor([0.5000]), 149: tensor([0.5000]), 150: tensor([0.9926]), 151: tensor([0.5000]), 152: tensor([0.5000]), 153: tensor([0.9926]), 154: tensor([0.9206]), 155: tensor([0.9926]), 156: tensor([0.5000]), 157: tensor([0.5000]), 158: tensor([0.9926]), 159: tensor([0.5000]), 160: tensor([0.5000]), 161: tensor([0.5000]), 162: tensor([0.5130]), 163: tensor([0.5000]), 164: tensor([0.9206]), 165: tensor([0.5000]), 167: tensor([0.5000]), 166: tensor([0.5000]), 168: tensor([0.5000]), 169: tensor([0.5995]), 170: tensor([1.]), 171: tensor([1.]), 172: tensor([0.9206]), 173: tensor([0.9206]), 174: tensor([0.5000]), 175: tensor([0.9890]), 176: tensor([1.]), 177: tensor([0.5000]), 179: tensor([0.9926]), 178: tensor([0.9206]), 181: tensor([0.5000]), 180: tensor([0.5000]), 182: tensor([0.5000]), 183: tensor([0.5000]), 184: tensor([0.9206]), 185: tensor([1.]), 186: tensor([1.]), 187: tensor([0.5000]), 188: tensor([0.5000]), 189: tensor([0.5000]), 190: tensor([0.9206]), 191: tensor([0.9206]), 192: tensor([0.5000]), 193: tensor([0.9206]), 195: tensor([0.9926]), 196: tensor([0.5000])}\n",
      "194\n",
      "186\n",
      "{8: {3: {186: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False)}}, 4: {77: {1: Linear(in_features=1, out_features=1, bias=False)}}, 2: {186: {194: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{186: {194: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{194: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([1.]), 2: tensor([0.]), 3: tensor([0.]), 4: tensor([0.9926]), 5: tensor([0.9926]), 6: tensor([0.9926]), 7: tensor([0.5000]), 8: tensor([0.9926]), 9: tensor([0.9926]), 10: tensor([0.5000]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.5000]), 14: tensor([0.9926]), 15: tensor([0.9964]), 16: tensor([0.9926]), 17: tensor([0.9926]), 19: tensor([0.5000]), 20: tensor([5.5424e-06]), 21: tensor([0.9926]), 22: tensor([0.5000]), 23: tensor([0.9926]), 24: tensor([0.9926]), 25: tensor([0.5000]), 26: tensor([0.9926]), 27: tensor([0.9926]), 28: tensor([0.5000]), 29: tensor([0.9926]), 30: tensor([0.5000]), 31: tensor([0.9926]), 32: tensor([0.5000]), 33: tensor([1.0000]), 34: tensor([0.5000]), 35: tensor([0.9926]), 36: tensor([0.9926]), 37: tensor([0.9926]), 38: tensor([0.5000]), 39: tensor([0.9926]), 40: tensor([0.0107]), 41: tensor([0.5000]), 42: tensor([0.9926]), 43: tensor([0.5000]), 44: tensor([0.5000]), 45: tensor([0.9926]), 46: tensor([0.5000]), 47: tensor([0.9926]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([1.]), 51: tensor([0.9926]), 52: tensor([0.5000]), 53: tensor([0.9926]), 54: tensor([0.9926]), 56: tensor([0.5000]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.5000]), 59: tensor([0.9926]), 60: tensor([0.9926]), 62: tensor([0.5000]), 61: tensor([1.0000]), 63: tensor([3.1323e-25]), 64: tensor([0.5000]), 65: tensor([0.9926]), 66: tensor([0.5000]), 67: tensor([0.9926]), 68: tensor([1.]), 69: tensor([0.9926]), 71: tensor([0.9926]), 70: tensor([0.5000]), 72: tensor([0.9964]), 73: tensor([0.9926]), 74: tensor([0.9926]), 75: tensor([0.9926]), 76: tensor([0.9926]), 78: tensor([0.5000]), 77: tensor([0.9998]), 79: tensor([0.9926]), 80: tensor([0.9926]), 82: tensor([0.9909]), 83: tensor([0.9926]), 84: tensor([0.9926]), 85: tensor([0.5000]), 86: tensor([0.9926]), 88: tensor([0.5000]), 87: tensor([0.9926]), 89: tensor([0.9926]), 91: tensor([0.9926]), 90: tensor([0.5000]), 92: tensor([1.0000]), 93: tensor([0.9926]), 94: tensor([0.9926]), 95: tensor([0.9926]), 96: tensor([0.5000]), 97: tensor([0.9926]), 99: tensor([0.9926]), 98: tensor([0.9926]), 100: tensor([0.5000]), 102: tensor([2.4260e-08]), 101: tensor([0.5000]), 103: tensor([0.9926]), 104: tensor([0.9742]), 105: tensor([0.9926]), 106: tensor([0.5000]), 107: tensor([0.9926]), 109: tensor([0.9926]), 108: tensor([0.5000]), 110: tensor([0.9926]), 111: tensor([0.9926]), 112: tensor([0.9926]), 113: tensor([0.5000]), 114: tensor([0.9926]), 115: tensor([0.9926]), 116: tensor([0.5000]), 117: tensor([0.9926]), 118: tensor([0.5000]), 120: tensor([0.9926]), 119: tensor([0.9926]), 121: tensor([0.9926]), 122: tensor([0.5000]), 123: tensor([0.9926]), 124: tensor([0.5008]), 125: tensor([0.5000]), 126: tensor([0.5000]), 127: tensor([0.9926]), 128: tensor([0.5001]), 129: tensor([0.9926]), 130: tensor([0.5000]), 131: tensor([0.9926]), 132: tensor([0.9926]), 133: tensor([0.9926]), 134: tensor([0.5000]), 135: tensor([0.9926]), 136: tensor([0.5000]), 138: tensor([0.9926]), 137: tensor([0.9926]), 139: tensor([0.5000]), 140: tensor([0.9813]), 141: tensor([0.9926]), 142: tensor([0.5000]), 143: tensor([0.5000]), 144: tensor([0.5901]), 145: tensor([0.9926]), 146: tensor([0.5122]), 147: tensor([0.9926]), 148: tensor([0.5000]), 149: tensor([0.9926]), 150: tensor([0.9926]), 151: tensor([0.5000]), 152: tensor([0.9926]), 153: tensor([0.9926]), 154: tensor([0.8221]), 155: tensor([0.9926]), 156: tensor([0.9926]), 157: tensor([0.9926]), 158: tensor([0.9926]), 159: tensor([0.5000]), 160: tensor([0.5000]), 161: tensor([0.9926]), 162: tensor([0.9206]), 163: tensor([0.5000]), 164: tensor([0.9926]), 165: tensor([0.9926]), 167: tensor([0.9926]), 166: tensor([0.9926]), 168: tensor([0.5000]), 169: tensor([0.5436]), 170: tensor([1.0000]), 171: tensor([1.]), 172: tensor([0.5000]), 173: tensor([0.9926]), 174: tensor([0.5000]), 175: tensor([0.9238]), 176: tensor([1.]), 177: tensor([0.9926]), 179: tensor([0.9926]), 178: tensor([0.5000]), 181: tensor([0.5000]), 180: tensor([0.0007]), 182: tensor([0.9926]), 183: tensor([0.9926]), 184: tensor([0.5000]), 185: tensor([1.]), 186: tensor([1.]), 187: tensor([0.9926]), 188: tensor([0.5000]), 189: tensor([0.9926]), 190: tensor([0.9926]), 191: tensor([0.5000]), 192: tensor([0.5000]), 193: tensor([0.5000]), 195: tensor([0.9926]), 196: tensor([0.9926])}\n",
      "194\n",
      "186\n",
      "{8: {3: {186: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False)}}, 4: {77: {1: Linear(in_features=1, out_features=1, bias=False)}}, 2: {186: {194: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{186: {194: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{194: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([0.]), 2: tensor([1.]), 3: tensor([0.]), 4: tensor([0.5000]), 5: tensor([0.9926]), 6: tensor([0.5000]), 7: tensor([0.9926]), 8: tensor([0.5000]), 9: tensor([0.5000]), 10: tensor([0.9926]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.9926]), 14: tensor([0.9926]), 15: tensor([1.0000]), 16: tensor([0.5000]), 17: tensor([0.5000]), 19: tensor([0.9926]), 20: tensor([5.5424e-06]), 21: tensor([0.5000]), 22: tensor([0.9926]), 23: tensor([0.9926]), 24: tensor([0.5000]), 25: tensor([0.9926]), 26: tensor([0.9926]), 27: tensor([0.5000]), 28: tensor([0.9926]), 29: tensor([0.9926]), 30: tensor([0.9926]), 31: tensor([0.9926]), 32: tensor([0.9926]), 33: tensor([1.0000]), 34: tensor([0.1965]), 35: tensor([0.5000]), 36: tensor([0.9926]), 37: tensor([0.5000]), 38: tensor([0.9926]), 39: tensor([0.5000]), 40: tensor([0.0107]), 41: tensor([0.9926]), 42: tensor([0.9926]), 43: tensor([0.9926]), 44: tensor([0.9926]), 45: tensor([0.9926]), 46: tensor([0.9926]), 47: tensor([0.5000]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([0.5000]), 51: tensor([0.5000]), 52: tensor([0.9926]), 53: tensor([0.9926]), 54: tensor([0.5000]), 56: tensor([0.9926]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.9926]), 59: tensor([0.5000]), 60: tensor([0.5000]), 62: tensor([0.9926]), 61: tensor([1.0000]), 63: tensor([0.9967]), 64: tensor([0.9926]), 65: tensor([0.9926]), 66: tensor([1.0000]), 67: tensor([0.5000]), 68: tensor([1.]), 69: tensor([0.9206]), 71: tensor([0.5000]), 70: tensor([0.9926]), 72: tensor([0.9964]), 73: tensor([0.5000]), 74: tensor([0.9206]), 75: tensor([0.5000]), 76: tensor([0.9926]), 78: tensor([0.9926]), 77: tensor([0.5000]), 79: tensor([0.5000]), 80: tensor([0.9926]), 82: tensor([0.9206]), 83: tensor([0.5000]), 84: tensor([0.9926]), 85: tensor([0.9926]), 86: tensor([0.9926]), 88: tensor([0.9926]), 87: tensor([0.5000]), 89: tensor([0.5000]), 91: tensor([0.5000]), 90: tensor([0.9926]), 92: tensor([0.0001]), 93: tensor([0.5000]), 94: tensor([0.5000]), 95: tensor([0.9926]), 96: tensor([0.9206]), 97: tensor([0.9926]), 99: tensor([0.5000]), 98: tensor([0.9926]), 100: tensor([0.9926]), 102: tensor([2.4260e-08]), 101: tensor([0.9926]), 103: tensor([0.9926]), 104: tensor([0.2192]), 105: tensor([0.5000]), 106: tensor([0.9926]), 107: tensor([0.9926]), 109: tensor([0.9926]), 108: tensor([0.9926]), 110: tensor([0.5000]), 111: tensor([0.9926]), 112: tensor([0.5000]), 113: tensor([0.9926]), 114: tensor([0.9926]), 115: tensor([0.9926]), 116: tensor([0.9926]), 117: tensor([0.9926]), 118: tensor([0.9997]), 120: tensor([0.5000]), 119: tensor([0.9926]), 121: tensor([0.9926]), 122: tensor([0.9926]), 123: tensor([0.9926]), 124: tensor([0.9926]), 125: tensor([0.9926]), 126: tensor([0.9926]), 127: tensor([0.9926]), 128: tensor([0.5001]), 129: tensor([0.9926]), 130: tensor([0.9926]), 131: tensor([0.9926]), 132: tensor([0.5000]), 133: tensor([0.5000]), 134: tensor([0.9926]), 135: tensor([0.5000]), 136: tensor([0.9926]), 138: tensor([0.5000]), 137: tensor([0.9926]), 139: tensor([0.9926]), 140: tensor([0.9923]), 141: tensor([0.5000]), 142: tensor([1.]), 143: tensor([8.9021e-09]), 144: tensor([0.9206]), 145: tensor([0.5000]), 146: tensor([0.9206]), 147: tensor([0.5000]), 148: tensor([0.9926]), 149: tensor([0.5000]), 150: tensor([0.9926]), 151: tensor([0.9926]), 152: tensor([0.5000]), 153: tensor([0.9926]), 154: tensor([0.9206]), 155: tensor([0.9926]), 156: tensor([0.5000]), 157: tensor([0.5000]), 158: tensor([0.9926]), 159: tensor([0.9926]), 160: tensor([0.9926]), 161: tensor([0.5000]), 162: tensor([0.5130]), 163: tensor([0.9926]), 164: tensor([0.9206]), 165: tensor([0.5000]), 167: tensor([0.5000]), 166: tensor([0.5000]), 168: tensor([0.9926]), 169: tensor([0.5995]), 170: tensor([1.]), 171: tensor([1.]), 172: tensor([0.9206]), 173: tensor([0.9206]), 174: tensor([0.9926]), 175: tensor([0.9890]), 176: tensor([1.]), 177: tensor([0.5000]), 179: tensor([0.9926]), 178: tensor([0.9206]), 181: tensor([0.9926]), 180: tensor([0.5000]), 182: tensor([0.5000]), 183: tensor([0.5000]), 184: tensor([0.9206]), 185: tensor([1.]), 186: tensor([1.]), 187: tensor([0.5000]), 188: tensor([0.9926]), 189: tensor([0.5000]), 190: tensor([0.9206]), 191: tensor([0.9206]), 192: tensor([0.9926]), 193: tensor([0.9206]), 195: tensor([0.9926]), 196: tensor([0.5000])}\n",
      "194\n",
      "186\n",
      "{8: {3: {186: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False)}}, 4: {77: {1: Linear(in_features=1, out_features=1, bias=False)}}, 2: {186: {194: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{186: {194: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{194: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([1.]), 2: tensor([1.]), 3: tensor([0.]), 4: tensor([0.9926]), 5: tensor([0.9926]), 6: tensor([0.9926]), 7: tensor([0.9926]), 8: tensor([0.9926]), 9: tensor([0.9926]), 10: tensor([0.9926]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.9926]), 14: tensor([0.9926]), 15: tensor([1.0000]), 16: tensor([0.9926]), 17: tensor([0.9926]), 19: tensor([0.9926]), 20: tensor([5.5424e-06]), 21: tensor([0.9926]), 22: tensor([0.9926]), 23: tensor([0.9926]), 24: tensor([0.9926]), 25: tensor([0.9926]), 26: tensor([0.9926]), 27: tensor([0.9926]), 28: tensor([0.9926]), 29: tensor([0.9926]), 30: tensor([0.9926]), 31: tensor([0.9926]), 32: tensor([0.9926]), 33: tensor([1.0000]), 34: tensor([0.1965]), 35: tensor([0.9926]), 36: tensor([0.9926]), 37: tensor([0.9926]), 38: tensor([0.9926]), 39: tensor([0.9926]), 40: tensor([0.0107]), 41: tensor([0.9926]), 42: tensor([0.9926]), 43: tensor([0.9926]), 44: tensor([0.9926]), 45: tensor([0.9926]), 46: tensor([0.9926]), 47: tensor([0.9926]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([1.]), 51: tensor([0.9926]), 52: tensor([0.9926]), 53: tensor([0.9926]), 54: tensor([0.9926]), 56: tensor([0.9926]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.9926]), 59: tensor([0.9926]), 60: tensor([0.9926]), 62: tensor([0.9926]), 61: tensor([1.0000]), 63: tensor([3.1323e-25]), 64: tensor([0.9926]), 65: tensor([0.9926]), 66: tensor([1.0000]), 67: tensor([0.9926]), 68: tensor([1.]), 69: tensor([0.9926]), 71: tensor([0.9926]), 70: tensor([0.9926]), 72: tensor([0.9964]), 73: tensor([0.9926]), 74: tensor([0.9926]), 75: tensor([0.9926]), 76: tensor([0.9926]), 78: tensor([0.9926]), 77: tensor([0.9998]), 79: tensor([0.9926]), 80: tensor([0.9926]), 82: tensor([0.9909]), 83: tensor([0.9926]), 84: tensor([0.9926]), 85: tensor([0.9926]), 86: tensor([0.9926]), 88: tensor([0.9926]), 87: tensor([0.9926]), 89: tensor([0.9926]), 91: tensor([0.9926]), 90: tensor([0.9926]), 92: tensor([0.0001]), 93: tensor([0.9926]), 94: tensor([0.9926]), 95: tensor([0.9926]), 96: tensor([0.5000]), 97: tensor([0.9926]), 99: tensor([0.9926]), 98: tensor([0.9926]), 100: tensor([0.9926]), 102: tensor([2.4260e-08]), 101: tensor([0.9926]), 103: tensor([0.9926]), 104: tensor([0.9742]), 105: tensor([0.9926]), 106: tensor([0.9926]), 107: tensor([0.9926]), 109: tensor([0.9926]), 108: tensor([0.9926]), 110: tensor([0.9926]), 111: tensor([0.9926]), 112: tensor([0.9926]), 113: tensor([0.9926]), 114: tensor([0.9926]), 115: tensor([0.9926]), 116: tensor([0.9926]), 117: tensor([0.9926]), 118: tensor([0.9997]), 120: tensor([0.9926]), 119: tensor([0.9926]), 121: tensor([0.9926]), 122: tensor([0.9926]), 123: tensor([0.9926]), 124: tensor([0.9926]), 125: tensor([0.9926]), 126: tensor([0.9926]), 127: tensor([0.9926]), 128: tensor([0.5001]), 129: tensor([0.9926]), 130: tensor([0.9926]), 131: tensor([0.9926]), 132: tensor([0.9926]), 133: tensor([0.9926]), 134: tensor([0.9926]), 135: tensor([0.9926]), 136: tensor([0.9926]), 138: tensor([0.9926]), 137: tensor([0.9926]), 139: tensor([0.9926]), 140: tensor([0.9923]), 141: tensor([0.9926]), 142: tensor([1.]), 143: tensor([0.5000]), 144: tensor([0.5901]), 145: tensor([0.9926]), 146: tensor([0.5122]), 147: tensor([0.9926]), 148: tensor([0.9926]), 149: tensor([0.9926]), 150: tensor([0.9926]), 151: tensor([0.9926]), 152: tensor([0.9926]), 153: tensor([0.9926]), 154: tensor([0.8221]), 155: tensor([0.9926]), 156: tensor([0.9926]), 157: tensor([0.9926]), 158: tensor([0.9926]), 159: tensor([0.9926]), 160: tensor([0.9926]), 161: tensor([0.9926]), 162: tensor([0.9206]), 163: tensor([0.9926]), 164: tensor([0.9926]), 165: tensor([0.9926]), 167: tensor([0.9926]), 166: tensor([0.9926]), 168: tensor([0.9926]), 169: tensor([0.5436]), 170: tensor([1.0000]), 171: tensor([1.]), 172: tensor([0.5000]), 173: tensor([0.9926]), 174: tensor([0.9926]), 175: tensor([0.9238]), 176: tensor([1.]), 177: tensor([0.9926]), 179: tensor([0.9926]), 178: tensor([0.5000]), 181: tensor([0.9926]), 180: tensor([0.0007]), 182: tensor([0.9926]), 183: tensor([0.9926]), 184: tensor([0.5000]), 185: tensor([1.]), 186: tensor([1.]), 187: tensor([0.9926]), 188: tensor([0.9926]), 189: tensor([0.9926]), 190: tensor([0.9926]), 191: tensor([0.5000]), 192: tensor([0.9926]), 193: tensor([0.5000]), 195: tensor([0.9926]), 196: tensor([0.9926])}\n",
      "194\n",
      "186\n",
      "{8: {3: {186: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 2: Linear(in_features=1, out_features=1, bias=False)}}, 4: {77: {1: Linear(in_features=1, out_features=1, bias=False)}}, 2: {186: {194: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{186: {194: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{194: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "Species: 3 fitness: 3.997838230694042 best fitness: 0.23529927870806525\n",
      "89\n",
      "Species: 0 fitness: 5.909599958525758 best fitness: 0.1\n",
      "Species: 1 fitness: 7.494493081019476 best fitness: 0.23076923076923078\n",
      "Species: 2 fitness: 4.015581091245015 best fitness: 0.42857142857142855\n",
      "90\n",
      "Species: 1 fitness: 7.663648711310491 best fitness: 0.25\n",
      "Species: 2 fitness: 4.6272522027675915 best fitness: 0.34615384615384615\n",
      "91\n",
      "Species: 0 fitness: 7.281084553400666 best fitness: 0.1\n",
      "Species: 1 fitness: 5.94852111462889 best fitness: 0.15517241379310345\n",
      "Species: 2 fitness: 4.000000953674316 best fitness: 2.0000009536743164\n",
      "92\n",
      "Species: 0 fitness: 7.148687971962828 best fitness: 0.16666666666666666\n",
      "Species: 1 fitness: 6.082910524095806 best fitness: 0.12857142857142856\n",
      "Species: 2 fitness: 4.28924332673733 best fitness: 0.3431250498845027\n",
      "93\n",
      "Species: 0 fitness: 7.450077879017792 best fitness: 0.15517241379310345\n",
      "Species: 1 fitness: 5.963170823029107 best fitness: 0.12857142857142856\n",
      "Species: 2 fitness: 4.70060789043253 best fitness: 0.408276384527033\n",
      "94\n",
      "Species: 0 fitness: 6.8884144936289085 best fitness: 0.16071428571428573\n",
      "Species: 1 fitness: 6.339591743516141 best fitness: 0.14754098360655737\n",
      "Species: 2 fitness: 5.578941160632719 best fitness: 0.29029886184200165\n",
      "Species: 3 fitness: 6.4999823570251465 best fitness: 4.4999823570251465\n",
      "95\n",
      "Species: 0 fitness: 6.602421184865443 best fitness: 0.21951219512195122\n",
      "Species: 1 fitness: 6.410051559960403 best fitness: 0.16666666666666666\n",
      "Species: 2 fitness: 5.393081585566202 best fitness: 0.3\n",
      "Species: 3 fitness: 6.490205726623537 best fitness: 0.36\n",
      "96\n",
      "Species: 0 fitness: 7.052289998531336 best fitness: 0.225\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([0.]), 2: tensor([0.]), 3: tensor([9.1348e-19]), 4: tensor([0.5000]), 5: tensor([0.9926]), 6: tensor([0.5000]), 7: tensor([0.5000]), 8: tensor([0.5000]), 9: tensor([0.5000]), 10: tensor([0.5000]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.5000]), 14: tensor([0.9926]), 15: tensor([0.9964]), 16: tensor([0.5000]), 17: tensor([0.5000]), 19: tensor([0.5000]), 20: tensor([5.5424e-06]), 21: tensor([0.5000]), 22: tensor([0.5000]), 23: tensor([0.9926]), 24: tensor([0.5000]), 25: tensor([0.5000]), 26: tensor([0.9926]), 27: tensor([0.5000]), 28: tensor([0.5000]), 29: tensor([0.9926]), 30: tensor([0.5000]), 31: tensor([0.9926]), 32: tensor([0.5000]), 33: tensor([1.0000]), 34: tensor([0.5000]), 35: tensor([0.5000]), 36: tensor([0.9926]), 37: tensor([0.5000]), 38: tensor([0.5000]), 39: tensor([0.5000]), 40: tensor([0.0107]), 41: tensor([0.5000]), 42: tensor([0.9926]), 43: tensor([0.5000]), 44: tensor([0.5000]), 45: tensor([0.9926]), 46: tensor([0.5000]), 47: tensor([0.5000]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([0.5000]), 51: tensor([0.5000]), 52: tensor([0.5000]), 53: tensor([0.9926]), 54: tensor([0.5000]), 56: tensor([0.5000]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.5000]), 59: tensor([0.5000]), 60: tensor([0.5000]), 62: tensor([0.5000]), 61: tensor([1.0000]), 63: tensor([0.9967]), 64: tensor([0.5000]), 65: tensor([0.9926]), 66: tensor([0.5000]), 67: tensor([0.5000]), 68: tensor([1.]), 69: tensor([0.9206]), 71: tensor([0.5000]), 70: tensor([0.5000]), 72: tensor([0.9964]), 73: tensor([0.5000]), 74: tensor([0.9206]), 75: tensor([0.5000]), 76: tensor([0.9926]), 78: tensor([0.5000]), 77: tensor([0.8628]), 79: tensor([0.5000]), 80: tensor([0.9926]), 82: tensor([0.9206]), 83: tensor([0.5000]), 84: tensor([0.9926]), 85: tensor([0.5000]), 86: tensor([0.9926]), 88: tensor([0.5000]), 87: tensor([0.5000]), 89: tensor([0.5000]), 91: tensor([0.5000]), 90: tensor([0.5000]), 92: tensor([1.0000]), 93: tensor([0.5000]), 94: tensor([0.5000]), 95: tensor([0.9926]), 96: tensor([0.9206]), 97: tensor([0.9926]), 99: tensor([0.5000]), 98: tensor([0.9926]), 100: tensor([0.5000]), 102: tensor([2.4260e-08]), 101: tensor([0.5000]), 103: tensor([0.9926]), 104: tensor([0.2192]), 105: tensor([0.5000]), 106: tensor([0.5000]), 107: tensor([0.9926]), 109: tensor([0.9926]), 108: tensor([0.5000]), 110: tensor([0.5000]), 111: tensor([0.9926]), 112: tensor([0.5000]), 113: tensor([0.5000]), 114: tensor([0.9926]), 115: tensor([0.9926]), 116: tensor([0.5000]), 117: tensor([0.9926]), 118: tensor([0.5000]), 120: tensor([0.5000]), 119: tensor([0.9926]), 121: tensor([0.9926]), 122: tensor([0.5000]), 123: tensor([0.9926]), 124: tensor([0.5008]), 125: tensor([0.5000]), 126: tensor([0.5000]), 127: tensor([0.9926]), 128: tensor([0.5001]), 129: tensor([0.9926]), 130: tensor([0.5000]), 131: tensor([0.9926]), 132: tensor([0.5000]), 133: tensor([0.5000]), 134: tensor([0.5000]), 135: tensor([0.5000]), 136: tensor([0.5000]), 138: tensor([0.5000]), 137: tensor([0.9926]), 139: tensor([0.5000]), 140: tensor([0.9813]), 141: tensor([0.5000]), 142: tensor([0.5000]), 143: tensor([8.9021e-09]), 144: tensor([0.9206]), 145: tensor([0.5000]), 146: tensor([0.9206]), 147: tensor([0.5000]), 148: tensor([0.5000]), 149: tensor([0.5000]), 150: tensor([0.9926]), 151: tensor([0.5000]), 152: tensor([0.5000]), 153: tensor([0.9926]), 154: tensor([0.9206]), 155: tensor([0.9926]), 156: tensor([0.5000]), 157: tensor([0.5000]), 158: tensor([0.9926]), 159: tensor([0.5000]), 160: tensor([0.5000]), 161: tensor([0.5000]), 162: tensor([0.5130]), 163: tensor([0.5000]), 164: tensor([0.9206]), 165: tensor([0.5000]), 167: tensor([0.5000]), 166: tensor([0.5000]), 168: tensor([0.5000]), 169: tensor([0.5995]), 170: tensor([1.]), 171: tensor([1.]), 172: tensor([0.9206]), 173: tensor([0.9206]), 174: tensor([0.5000]), 175: tensor([0.9890]), 176: tensor([1.]), 177: tensor([0.5000]), 179: tensor([0.9926]), 178: tensor([0.9206]), 181: tensor([0.5000]), 180: tensor([0.5000]), 182: tensor([0.5000]), 183: tensor([0.5000]), 184: tensor([0.9206]), 185: tensor([1.]), 186: tensor([0.5000]), 187: tensor([0.5000]), 188: tensor([0.5000]), 189: tensor([0.5000]), 190: tensor([0.9206]), 191: tensor([0.9206]), 192: tensor([0.5000]), 193: tensor([0.9206]), 195: tensor([0.9926]), 196: tensor([0.5000]), 197: tensor([0.9926]), 198: tensor([0.9206]), 199: tensor([0.9926]), 200: tensor([0.6869]), 201: tensor([0.9206]), 202: tensor([0.9926]), 203: tensor([0.5731]), 204: tensor([0.5000]), 205: tensor([0.9206]), 206: tensor([0.9926]), 207: tensor([0.9926]), 208: tensor([0.9206]), 209: tensor([0.5000]), 210: tensor([0.5000]), 211: tensor([0.5000])}\n",
      "212\n",
      "3\n",
      "{4: {77: {180: Linear(in_features=1, out_features=1, bias=False)}}, 8: {3: {1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}}, 2: {180: {1: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([1.]), 2: tensor([0.]), 3: tensor([8.2964e-10]), 4: tensor([0.9926]), 5: tensor([0.9926]), 6: tensor([0.9926]), 7: tensor([0.5000]), 8: tensor([0.9926]), 9: tensor([0.9926]), 10: tensor([0.5000]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.5000]), 14: tensor([0.9926]), 15: tensor([0.9964]), 16: tensor([0.9926]), 17: tensor([0.9926]), 19: tensor([0.5000]), 20: tensor([5.5424e-06]), 21: tensor([0.9926]), 22: tensor([0.5000]), 23: tensor([0.9926]), 24: tensor([0.9926]), 25: tensor([0.5000]), 26: tensor([0.9926]), 27: tensor([0.9926]), 28: tensor([0.5000]), 29: tensor([0.9926]), 30: tensor([0.5000]), 31: tensor([0.9926]), 32: tensor([0.5000]), 33: tensor([1.0000]), 34: tensor([0.5000]), 35: tensor([0.9926]), 36: tensor([0.9926]), 37: tensor([0.9926]), 38: tensor([0.5000]), 39: tensor([0.9926]), 40: tensor([0.0107]), 41: tensor([0.5000]), 42: tensor([0.9926]), 43: tensor([0.5000]), 44: tensor([0.5000]), 45: tensor([0.9926]), 46: tensor([0.5000]), 47: tensor([0.9926]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([1.]), 51: tensor([0.9926]), 52: tensor([0.5000]), 53: tensor([0.9926]), 54: tensor([0.9926]), 56: tensor([0.5000]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.5000]), 59: tensor([0.9926]), 60: tensor([0.9926]), 62: tensor([0.5000]), 61: tensor([1.0000]), 63: tensor([3.1323e-25]), 64: tensor([0.5000]), 65: tensor([0.9926]), 66: tensor([0.5000]), 67: tensor([0.9926]), 68: tensor([1.]), 69: tensor([0.9926]), 71: tensor([0.9926]), 70: tensor([0.5000]), 72: tensor([0.9964]), 73: tensor([0.9926]), 74: tensor([0.9926]), 75: tensor([0.9926]), 76: tensor([0.9926]), 78: tensor([0.5000]), 77: tensor([0.9751]), 79: tensor([0.9926]), 80: tensor([0.9926]), 82: tensor([0.9909]), 83: tensor([0.9926]), 84: tensor([0.9926]), 85: tensor([0.5000]), 86: tensor([0.9926]), 88: tensor([0.5000]), 87: tensor([0.9926]), 89: tensor([0.9926]), 91: tensor([0.9926]), 90: tensor([0.5000]), 92: tensor([1.0000]), 93: tensor([0.9926]), 94: tensor([0.9926]), 95: tensor([0.9926]), 96: tensor([0.5000]), 97: tensor([0.9926]), 99: tensor([0.9926]), 98: tensor([0.9926]), 100: tensor([0.5000]), 102: tensor([2.4260e-08]), 101: tensor([0.5000]), 103: tensor([0.9926]), 104: tensor([0.9742]), 105: tensor([0.9926]), 106: tensor([0.5000]), 107: tensor([0.9926]), 109: tensor([0.9926]), 108: tensor([0.5000]), 110: tensor([0.9926]), 111: tensor([0.9926]), 112: tensor([0.9926]), 113: tensor([0.5000]), 114: tensor([0.9926]), 115: tensor([0.9926]), 116: tensor([0.5000]), 117: tensor([0.9926]), 118: tensor([0.5000]), 120: tensor([0.9926]), 119: tensor([0.9926]), 121: tensor([0.9926]), 122: tensor([0.5000]), 123: tensor([0.9926]), 124: tensor([0.5008]), 125: tensor([0.5000]), 126: tensor([0.5000]), 127: tensor([0.9926]), 128: tensor([0.5001]), 129: tensor([0.9926]), 130: tensor([0.5000]), 131: tensor([0.9926]), 132: tensor([0.9926]), 133: tensor([0.9926]), 134: tensor([0.5000]), 135: tensor([0.9926]), 136: tensor([0.5000]), 138: tensor([0.9926]), 137: tensor([0.9926]), 139: tensor([0.5000]), 140: tensor([0.9813]), 141: tensor([0.9926]), 142: tensor([0.5000]), 143: tensor([0.5000]), 144: tensor([0.5901]), 145: tensor([0.9926]), 146: tensor([0.5122]), 147: tensor([0.9926]), 148: tensor([0.5000]), 149: tensor([0.9926]), 150: tensor([0.9926]), 151: tensor([0.5000]), 152: tensor([0.9926]), 153: tensor([0.9926]), 154: tensor([0.8221]), 155: tensor([0.9926]), 156: tensor([0.9926]), 157: tensor([0.9926]), 158: tensor([0.9926]), 159: tensor([0.5000]), 160: tensor([0.5000]), 161: tensor([0.9926]), 162: tensor([0.9206]), 163: tensor([0.5000]), 164: tensor([0.9926]), 165: tensor([0.9926]), 167: tensor([0.9926]), 166: tensor([0.9926]), 168: tensor([0.5000]), 169: tensor([0.5436]), 170: tensor([1.0000]), 171: tensor([1.]), 172: tensor([0.5000]), 173: tensor([0.9926]), 174: tensor([0.5000]), 175: tensor([0.9238]), 176: tensor([1.]), 177: tensor([0.9926]), 179: tensor([0.9926]), 178: tensor([0.5000]), 181: tensor([0.5000]), 180: tensor([0.9968]), 182: tensor([0.9926]), 183: tensor([0.9926]), 184: tensor([0.5000]), 185: tensor([1.]), 186: tensor([0.5000]), 187: tensor([0.9926]), 188: tensor([0.5000]), 189: tensor([0.9926]), 190: tensor([0.9926]), 191: tensor([0.5000]), 192: tensor([0.5000]), 193: tensor([0.5000]), 195: tensor([0.9926]), 196: tensor([0.9926]), 197: tensor([0.9926]), 198: tensor([0.5000]), 199: tensor([0.9926]), 200: tensor([0.5000]), 201: tensor([0.9926]), 202: tensor([0.9926]), 203: tensor([0.9409]), 204: tensor([0.9999]), 205: tensor([0.5000]), 206: tensor([0.9926]), 207: tensor([0.9926]), 208: tensor([0.5002]), 209: tensor([0.5000]), 210: tensor([0.5000]), 211: tensor([0.5000])}\n",
      "212\n",
      "3\n",
      "{4: {77: {180: Linear(in_features=1, out_features=1, bias=False)}}, 8: {3: {1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}}, 2: {180: {1: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([0.]), 2: tensor([1.]), 3: tensor([0.]), 4: tensor([0.5000]), 5: tensor([0.9926]), 6: tensor([0.5000]), 7: tensor([0.9926]), 8: tensor([0.5000]), 9: tensor([0.5000]), 10: tensor([0.9926]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.9926]), 14: tensor([0.9926]), 15: tensor([1.0000]), 16: tensor([0.5000]), 17: tensor([0.5000]), 19: tensor([0.9926]), 20: tensor([5.5424e-06]), 21: tensor([0.5000]), 22: tensor([0.9926]), 23: tensor([0.9926]), 24: tensor([0.5000]), 25: tensor([0.9926]), 26: tensor([0.9926]), 27: tensor([0.5000]), 28: tensor([0.9926]), 29: tensor([0.9926]), 30: tensor([0.9926]), 31: tensor([0.9926]), 32: tensor([0.9926]), 33: tensor([1.0000]), 34: tensor([0.1965]), 35: tensor([0.5000]), 36: tensor([0.9926]), 37: tensor([0.5000]), 38: tensor([0.9926]), 39: tensor([0.5000]), 40: tensor([0.0107]), 41: tensor([0.9926]), 42: tensor([0.9926]), 43: tensor([0.9926]), 44: tensor([0.9926]), 45: tensor([0.9926]), 46: tensor([0.9926]), 47: tensor([0.5000]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([0.5000]), 51: tensor([0.5000]), 52: tensor([0.9926]), 53: tensor([0.9926]), 54: tensor([0.5000]), 56: tensor([0.9926]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.9926]), 59: tensor([0.5000]), 60: tensor([0.5000]), 62: tensor([0.9926]), 61: tensor([1.0000]), 63: tensor([0.9967]), 64: tensor([0.9926]), 65: tensor([0.9926]), 66: tensor([1.0000]), 67: tensor([0.5000]), 68: tensor([1.]), 69: tensor([0.9206]), 71: tensor([0.5000]), 70: tensor([0.9926]), 72: tensor([0.9964]), 73: tensor([0.5000]), 74: tensor([0.9206]), 75: tensor([0.5000]), 76: tensor([0.9926]), 78: tensor([0.9926]), 77: tensor([0.8628]), 79: tensor([0.5000]), 80: tensor([0.9926]), 82: tensor([0.9206]), 83: tensor([0.5000]), 84: tensor([0.9926]), 85: tensor([0.9926]), 86: tensor([0.9926]), 88: tensor([0.9926]), 87: tensor([0.5000]), 89: tensor([0.5000]), 91: tensor([0.5000]), 90: tensor([0.9926]), 92: tensor([0.0001]), 93: tensor([0.5000]), 94: tensor([0.5000]), 95: tensor([0.9926]), 96: tensor([0.9206]), 97: tensor([0.9926]), 99: tensor([0.5000]), 98: tensor([0.9926]), 100: tensor([0.9926]), 102: tensor([2.4260e-08]), 101: tensor([0.9926]), 103: tensor([0.9926]), 104: tensor([0.2192]), 105: tensor([0.5000]), 106: tensor([0.9926]), 107: tensor([0.9926]), 109: tensor([0.9926]), 108: tensor([0.9926]), 110: tensor([0.5000]), 111: tensor([0.9926]), 112: tensor([0.5000]), 113: tensor([0.9926]), 114: tensor([0.9926]), 115: tensor([0.9926]), 116: tensor([0.9926]), 117: tensor([0.9926]), 118: tensor([0.9997]), 120: tensor([0.5000]), 119: tensor([0.9926]), 121: tensor([0.9926]), 122: tensor([0.9926]), 123: tensor([0.9926]), 124: tensor([0.9926]), 125: tensor([0.9926]), 126: tensor([0.9926]), 127: tensor([0.9926]), 128: tensor([0.5001]), 129: tensor([0.9926]), 130: tensor([0.9926]), 131: tensor([0.9926]), 132: tensor([0.5000]), 133: tensor([0.5000]), 134: tensor([0.9926]), 135: tensor([0.5000]), 136: tensor([0.9926]), 138: tensor([0.5000]), 137: tensor([0.9926]), 139: tensor([0.9926]), 140: tensor([0.9923]), 141: tensor([0.5000]), 142: tensor([1.]), 143: tensor([8.9021e-09]), 144: tensor([0.9206]), 145: tensor([0.5000]), 146: tensor([0.9206]), 147: tensor([0.5000]), 148: tensor([0.9926]), 149: tensor([0.5000]), 150: tensor([0.9926]), 151: tensor([0.9926]), 152: tensor([0.5000]), 153: tensor([0.9926]), 154: tensor([0.9206]), 155: tensor([0.9926]), 156: tensor([0.5000]), 157: tensor([0.5000]), 158: tensor([0.9926]), 159: tensor([0.9926]), 160: tensor([0.9926]), 161: tensor([0.5000]), 162: tensor([0.5130]), 163: tensor([0.9926]), 164: tensor([0.9206]), 165: tensor([0.5000]), 167: tensor([0.5000]), 166: tensor([0.5000]), 168: tensor([0.9926]), 169: tensor([0.5995]), 170: tensor([1.]), 171: tensor([1.]), 172: tensor([0.9206]), 173: tensor([0.9206]), 174: tensor([0.9926]), 175: tensor([0.9890]), 176: tensor([1.]), 177: tensor([0.5000]), 179: tensor([0.9926]), 178: tensor([0.9206]), 181: tensor([0.9926]), 180: tensor([0.5000]), 182: tensor([0.5000]), 183: tensor([0.5000]), 184: tensor([0.9206]), 185: tensor([1.]), 186: tensor([0.5000]), 187: tensor([0.5000]), 188: tensor([0.9926]), 189: tensor([0.5000]), 190: tensor([0.9206]), 191: tensor([0.9206]), 192: tensor([0.9926]), 193: tensor([0.9206]), 195: tensor([0.9926]), 196: tensor([0.5000]), 197: tensor([0.9926]), 198: tensor([0.9206]), 199: tensor([0.9926]), 200: tensor([0.6869]), 201: tensor([0.9206]), 202: tensor([0.9926]), 203: tensor([0.5731]), 204: tensor([0.5000]), 205: tensor([0.9926]), 206: tensor([0.9926]), 207: tensor([0.9926]), 208: tensor([0.9206]), 209: tensor([0.9926]), 210: tensor([0.9926]), 211: tensor([0.9926])}\n",
      "212\n",
      "3\n",
      "{4: {77: {180: Linear(in_features=1, out_features=1, bias=False)}}, 8: {3: {1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}}, 2: {180: {1: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "KeyError\n",
      "{0: tensor([1.]), 1: tensor([1.]), 2: tensor([1.]), 3: tensor([0.]), 4: tensor([0.9926]), 5: tensor([0.9926]), 6: tensor([0.9926]), 7: tensor([0.9926]), 8: tensor([0.9926]), 9: tensor([0.9926]), 10: tensor([0.9926]), 11: tensor([0.9926]), 12: tensor([0.9926]), 13: tensor([0.9926]), 14: tensor([0.9926]), 15: tensor([1.0000]), 16: tensor([0.9926]), 17: tensor([0.9926]), 19: tensor([0.9926]), 20: tensor([5.5424e-06]), 21: tensor([0.9926]), 22: tensor([0.9926]), 23: tensor([0.9926]), 24: tensor([0.9926]), 25: tensor([0.9926]), 26: tensor([0.9926]), 27: tensor([0.9926]), 28: tensor([0.9926]), 29: tensor([0.9926]), 30: tensor([0.9926]), 31: tensor([0.9926]), 32: tensor([0.9926]), 33: tensor([1.0000]), 34: tensor([0.1965]), 35: tensor([0.9926]), 36: tensor([0.9926]), 37: tensor([0.9926]), 38: tensor([0.9926]), 39: tensor([0.9926]), 40: tensor([0.0107]), 41: tensor([0.9926]), 42: tensor([0.9926]), 43: tensor([0.9926]), 44: tensor([0.9926]), 45: tensor([0.9926]), 46: tensor([0.9926]), 47: tensor([0.9926]), 48: tensor([1.]), 49: tensor([0.9926]), 50: tensor([1.]), 51: tensor([0.9926]), 52: tensor([0.9926]), 53: tensor([0.9926]), 54: tensor([0.9926]), 56: tensor([0.9926]), 55: tensor([0.9926]), 57: tensor([0.0924]), 58: tensor([0.9926]), 59: tensor([0.9926]), 60: tensor([0.9926]), 62: tensor([0.9926]), 61: tensor([1.0000]), 63: tensor([3.1323e-25]), 64: tensor([0.9926]), 65: tensor([0.9926]), 66: tensor([1.0000]), 67: tensor([0.9926]), 68: tensor([1.]), 69: tensor([0.9926]), 71: tensor([0.9926]), 70: tensor([0.9926]), 72: tensor([0.9964]), 73: tensor([0.9926]), 74: tensor([0.9926]), 75: tensor([0.9926]), 76: tensor([0.9926]), 78: tensor([0.9926]), 77: tensor([0.9751]), 79: tensor([0.9926]), 80: tensor([0.9926]), 82: tensor([0.9909]), 83: tensor([0.9926]), 84: tensor([0.9926]), 85: tensor([0.9926]), 86: tensor([0.9926]), 88: tensor([0.9926]), 87: tensor([0.9926]), 89: tensor([0.9926]), 91: tensor([0.9926]), 90: tensor([0.9926]), 92: tensor([0.0001]), 93: tensor([0.9926]), 94: tensor([0.9926]), 95: tensor([0.9926]), 96: tensor([0.5000]), 97: tensor([0.9926]), 99: tensor([0.9926]), 98: tensor([0.9926]), 100: tensor([0.9926]), 102: tensor([2.4260e-08]), 101: tensor([0.9926]), 103: tensor([0.9926]), 104: tensor([0.9742]), 105: tensor([0.9926]), 106: tensor([0.9926]), 107: tensor([0.9926]), 109: tensor([0.9926]), 108: tensor([0.9926]), 110: tensor([0.9926]), 111: tensor([0.9926]), 112: tensor([0.9926]), 113: tensor([0.9926]), 114: tensor([0.9926]), 115: tensor([0.9926]), 116: tensor([0.9926]), 117: tensor([0.9926]), 118: tensor([0.9997]), 120: tensor([0.9926]), 119: tensor([0.9926]), 121: tensor([0.9926]), 122: tensor([0.9926]), 123: tensor([0.9926]), 124: tensor([0.9926]), 125: tensor([0.9926]), 126: tensor([0.9926]), 127: tensor([0.9926]), 128: tensor([0.5001]), 129: tensor([0.9926]), 130: tensor([0.9926]), 131: tensor([0.9926]), 132: tensor([0.9926]), 133: tensor([0.9926]), 134: tensor([0.9926]), 135: tensor([0.9926]), 136: tensor([0.9926]), 138: tensor([0.9926]), 137: tensor([0.9926]), 139: tensor([0.9926]), 140: tensor([0.9923]), 141: tensor([0.9926]), 142: tensor([1.]), 143: tensor([0.5000]), 144: tensor([0.5901]), 145: tensor([0.9926]), 146: tensor([0.5122]), 147: tensor([0.9926]), 148: tensor([0.9926]), 149: tensor([0.9926]), 150: tensor([0.9926]), 151: tensor([0.9926]), 152: tensor([0.9926]), 153: tensor([0.9926]), 154: tensor([0.8221]), 155: tensor([0.9926]), 156: tensor([0.9926]), 157: tensor([0.9926]), 158: tensor([0.9926]), 159: tensor([0.9926]), 160: tensor([0.9926]), 161: tensor([0.9926]), 162: tensor([0.9206]), 163: tensor([0.9926]), 164: tensor([0.9926]), 165: tensor([0.9926]), 167: tensor([0.9926]), 166: tensor([0.9926]), 168: tensor([0.9926]), 169: tensor([0.5436]), 170: tensor([1.0000]), 171: tensor([1.]), 172: tensor([0.5000]), 173: tensor([0.9926]), 174: tensor([0.9926]), 175: tensor([0.9238]), 176: tensor([1.]), 177: tensor([0.9926]), 179: tensor([0.9926]), 178: tensor([0.5000]), 181: tensor([0.9926]), 180: tensor([0.9968]), 182: tensor([0.9926]), 183: tensor([0.9926]), 184: tensor([0.5000]), 185: tensor([1.]), 186: tensor([0.5000]), 187: tensor([0.9926]), 188: tensor([0.9926]), 189: tensor([0.9926]), 190: tensor([0.9926]), 191: tensor([0.5000]), 192: tensor([0.9926]), 193: tensor([0.5000]), 195: tensor([0.9926]), 196: tensor([0.9926]), 197: tensor([0.9926]), 198: tensor([0.5000]), 199: tensor([0.9926]), 200: tensor([0.5000]), 201: tensor([0.9926]), 202: tensor([0.9926]), 203: tensor([0.9409]), 204: tensor([0.9999]), 205: tensor([0.5000]), 206: tensor([0.9926]), 207: tensor([0.9926]), 208: tensor([0.5002]), 209: tensor([0.9926]), 210: tensor([0.9926]), 211: tensor([0.9926])}\n",
      "212\n",
      "3\n",
      "{4: {77: {180: Linear(in_features=1, out_features=1, bias=False)}}, 8: {3: {1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}}, 2: {180: {1: Linear(in_features=1, out_features=1, bias=False)}}}\n",
      "{3: {1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}}\n",
      "{1: Linear(in_features=1, out_features=1, bias=False), 0: Linear(in_features=1, out_features=1, bias=False), 77: Linear(in_features=1, out_features=1, bias=False), 212: Linear(in_features=1, out_features=1, bias=False)}\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "Species: 1 fitness: 5.551674928238147 best fitness: 0.13432835820895522\n",
      "Species: 2 fitness: 6.146311305463314 best fitness: 0.5624706149101257\n",
      "Species: 3 fitness: 7.021138879987926 best fitness: 0.3333333333333333\n",
      "97\n",
      "Species: 0 fitness: 6.894320173697034 best fitness: 0.20454545454545456\n",
      "Species: 1 fitness: 6.768442205588019 best fitness: 0.15\n",
      "Species: 2 fitness: 5.936944176169003 best fitness: 0.5294112598194796\n",
      "Species: 3 fitness: 6.835339550314281 best fitness: 0.3103448275862069\n",
      "98\n",
      "Species: 0 fitness: 6.264083828244891 best fitness: 0.21428571428571427\n",
      "Species: 1 fitness: 6.100434030547284 best fitness: 0.13636363636363635\n",
      "Species: 2 fitness: 6.041745597665959 best fitness: 0.40905146165327594\n",
      "Species: 3 fitness: 7.991109418869021 best fitness: 0.45\n",
      "99\n",
      "Species: 0 fitness: 7.545229371001084 best fitness: 0.21951219512195122\n",
      "Species: 1 fitness: 5.590973002910615 best fitness: 0.18\n",
      "Species: 2 fitness: 6.571425186263191 best fitness: 0.33333301544189453\n",
      "Species: 3 fitness: 7.408729147166014 best fitness: 0.28125\n",
      "100\n",
      "Species: 0 fitness: 7.654022450716994 best fitness: 0.16981132075471697\n",
      "Species: 1 fitness: 6.377634877382325 best fitness: 0.20930232558139536\n",
      "Species: 2 fitness: 6.964217644471388 best fitness: 0.34615384615384615\n",
      "Species: 3 fitness: 7.056909101349968 best fitness: 0.32142857142857145\n",
      "101\n",
      "Species: 0 fitness: 6.96890714019537 best fitness: 0.1875\n",
      "Species: 1 fitness: 5.9153411014407276 best fitness: 0.17647058823529413\n",
      "Species: 2 fitness: 6.781278009000033 best fitness: 0.391304347826087\n",
      "Species: 3 fitness: 6.9285964114325385 best fitness: 0.32142857142857145\n",
      "102\n",
      "Species: 1 fitness: 6.149094918194937 best fitness: 0.17647058823529413\n",
      "Species: 2 fitness: 6.908403616398573 best fitness: 0.28125\n",
      "Species: 3 fitness: 6.882126698493959 best fitness: 0.36\n",
      "103\n",
      "Species: 1 fitness: 7.253213238071751 best fitness: 0.24424029685355522\n",
      "Species: 2 fitness: 8.047305595043099 best fitness: 0.20930232558139536\n",
      "104\n",
      "Species: 0 fitness: 6.9887725361462305 best fitness: 0.10344834163271148\n",
      "Species: 1 fitness: 6.308873920213609 best fitness: 0.14285717313251797\n",
      "105\n",
      "Species: 0 fitness: 7.00252289772033 best fitness: 0.10588491103228401\n",
      "Species: 1 fitness: 6.829428812173703 best fitness: 0.13846153846153847\n",
      "106\n",
      "Species: 0 fitness: 6.283416348767561 best fitness: 0.10843373493975904\n",
      "Species: 1 fitness: 7.409682327242038 best fitness: 0.23093049917648087\n",
      "107\n",
      "Species: 0 fitness: 6.250137216166445 best fitness: 0.16357149575885974\n",
      "Species: 1 fitness: 7.001257480801767 best fitness: 0.14212211402686867\n",
      "108\n",
      "Species: 0 fitness: 6.095566816713624 best fitness: 0.10346261386213632\n",
      "Species: 1 fitness: 7.186028514589582 best fitness: 0.2536177256750682\n",
      "109\n",
      "Species: 0 fitness: 5.924348613110984 best fitness: 0.11227764734407751\n",
      "Species: 1 fitness: 8.062237192602721 best fitness: 0.23506857367122874\n",
      "110\n",
      "Species: 0 fitness: 6.937586864303138 best fitness: 0.15769051944508272\n",
      "Species: 1 fitness: 8.020259989224948 best fitness: 0.24615361140324518\n",
      "111\n",
      "Species: 0 fitness: 5.960233330726622 best fitness: 0.12887111391339984\n",
      "Species: 1 fitness: 8.320210945606227 best fitness: 0.2\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "random.seed(14)\n",
    "\n",
    "initial_species = Species(np.random.choice(genotypes), genotypes, distance_delta)\n",
    "\n",
    "evolved_species, solutions = evolve(\n",
    "    features=inputs, \n",
    "    target=targets, \n",
    "    fitness_function=xor_fitness, \n",
    "    stop_at_fitness=16, \n",
    "    n_generations=1000,\n",
    "    species=[initial_species], \n",
    "    fitness_survival_rate=fitness_survival_rate, \n",
    "    interspecies_mate_rate=interspecies_mate_rate, \n",
    "    distance_delta=distance_delta,\n",
    "    largest_species_linkadd_rate=mutate_add_link_prob_large_pop,\n",
    "    \n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [(<__main__.Genotype at 0x7f03260a8790>, 16.0)]}"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m nn\u001b[39m=\u001b[39m NeuralNetwork(solutions[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m fitness \u001b[39m=\u001b[39m xor_fitness(nn, inputs, targets, print_fitness\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "nn= NeuralNetwork(solutions[0][0][0])\n",
    "fitness = xor_fitness(nn, inputs, targets, print_fitness=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(<__main__.Genotype at 0x7f0337511910>, 8.218399047851562)]}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evolved_species[0].genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node genes:\n",
      "   innovation_number  node_level\n",
      "0                  0           0\n",
      "1                  1           0\n",
      "2                  2           0\n",
      "3                  3          12\n",
      "Connection genes:\n",
      "   innovation_number  in_node  out_node    weight  is_disabled\n",
      "0                  1        0         3 -0.279954        False\n",
      "1                  2        1         3  0.321729        False\n",
      "2                  3        2         3  0.414256        False\n"
     ]
    }
   ],
   "source": [
    "evolved_species[0].genotypes[2].print_genotype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proportions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39mcumsum([\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m proportions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'proportions' is not defined"
     ]
    }
   ],
   "source": [
    "np.cumsum([0] + proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 2, 3])"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3,345,1.3])\n",
    "np.argsort(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3355])"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_fitness(networks[0], inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Genotype.__init__() missing 2 required positional arguments: 'c2' and 'c3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10000\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     connection_genes \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         Connection_Gene(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(), \u001b[39mFalse\u001b[39;00m, connection_gene_history), \u001b[39m# bias\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         Connection_Gene(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(), \u001b[39mFalse\u001b[39;00m, connection_gene_history), \u001b[39m# input 1 \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         Connection_Gene(\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(), \u001b[39mFalse\u001b[39;00m, connection_gene_history), \u001b[39m# input 2\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     ]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     genotype \u001b[39m=\u001b[39m Genotype(node_genes, connection_genes, node_gene_history, connection_gene_history, mutate_weight_prob, mutate_weight_perturb, mutate_weight_random, mutate_add_node_prob, mutate_add_node_prob_large_pop, mutate_add_link_prob)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     genotype\u001b[39m.\u001b[39mmutate()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/NEAT_NeuroEvolution/neat.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     genotype\u001b[39m.\u001b[39mmutate()\n",
      "\u001b[0;31mTypeError\u001b[0m: Genotype.__init__() missing 2 required positional arguments: 'c2' and 'c3'"
     ]
    }
   ],
   "source": [
    "fitness = 0\n",
    "best_genotype = None\n",
    "for _ in range(10000):\n",
    "    \n",
    "    connection_genes = [\n",
    "        Connection_Gene(0, 3, np.random.normal(), False, connection_gene_history), # bias\n",
    "        Connection_Gene(1, 3, np.random.normal(), False, connection_gene_history), # input 1 \n",
    "        Connection_Gene(2, 3, np.random.normal(), False, connection_gene_history), # input 2\n",
    "    ]\n",
    "    \n",
    "    genotype = Genotype(node_genes, connection_genes, node_gene_history, connection_gene_history, mutate_weight_prob, mutate_weight_perturb, mutate_weight_random, mutate_add_node_prob, mutate_add_node_prob_large_pop, mutate_add_link_prob)\n",
    "    genotype.mutate()\n",
    "    genotype.mutate()\n",
    "    genotype.mutate()\n",
    "    genotype.mutate()\n",
    "    temp_fitness = xor_fitness(NeuralNetwork(genotype), inputs, targets)\n",
    "    if temp_fitness > fitness:\n",
    "        fitness = temp_fitness\n",
    "        best_genotype = genotype\n",
    "        print('===== new best fitness', fitness)\n",
    "        xor_fitness(NeuralNetwork(genotype), inputs, targets, print_fitness=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotype1.print_genotype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks[2].print_nn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
